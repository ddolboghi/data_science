{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZoLq2m6FuZx9"
   },
   "source": [
    "# 3학년 겨울방학 부산 스마트아카데미 교육 \n",
    "# 2023년 1월 2일"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-2b9BgVfuX9g"
   },
   "source": [
    "이정원 강사님 (mentor1023@daum.net, 010-4007-3276\n",
    "\n",
    "암기X, 그때 그떄 필요한 부분 summary <- 오류 해결 경험이 노하우, 오탈자 주의\n",
    "\n",
    "분석 공부는 전체 흐름 > 필요 개념 > 활용 방법 > 수학적 접근 순\n",
    "\n",
    "Q&A:\n",
    "딥러닝의 대학원 필요성? -> 그렇진 않음, 논문 작성 경험(결과 분석, 상관관계 해석 등에서의 우위), 석사보단 박사를 우대(깊이 있는 연구 경험, 언어소통 가능)\n",
    "\n",
    "수료시까지 석사급의 능력을 가지면 문제 없다는 답변\n",
    "\n",
    "기업의 JAVA선호? -> 우리나라 전자정부 플랫폼은 자바로 구성, 따라서 공공프로젝트의 경우엔 모두 자바로 작성해야함. 세계적인 추이는 파이썬이기도 함. 파이썬은 백엔드에서 머신러닝과 딥러닝에서 강세. 기업 프로젝트에서 파이썬 선호. 결국 2가지 모두 다룰 줄 알아야 함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NGspiNeQuzb6"
   },
   "source": [
    "**디지털 트랜스포메이션(DT) 기술**\n",
    "\n",
    "스마트팩토리, 스마트시티 -> 완전 자동화, 융합\n",
    "\n",
    "스마트? -> **ICBM(IOT Cloud Bigdata (Blockchain) Mobile (Security)) **\n",
    "\n",
    "수집 처리 분석 머신러닝 딥러닝 서비스\n",
    "IOT는 수집에 포함. 연결은 Mobile을 사용. Cloud는 시스템 자원 배분->플랫폼을 만들기위해(시스템 구축의 기반). Bigdata에서는 데이터 수집, 보관용으로 사용. -> 구글드라이브, 구글오피스, notion, ms365 등\n",
    "\n",
    "빅데이터 시스템이 실제로 있어야(빅데이터 플랫폼, 하둡-자바, 카프카-파이썬 등 *프로젝트 진행 시에 사용해도 된다.) 서비스가 가능. 여기선 분석을 먼저 배우고, 플랫폼을 만든다(엔지니어의 영역). \n",
    "\n",
    "adp,adsp(지금은 X, 프로젝트 진행 즈음)\n",
    "\n",
    "블록체인은 시간날때 개념 정도만, 암호화기술. 가상화폐는 블록체인을 활용한 서비스\n",
    "\n",
    "5G,6G의 실내,지하 환경에서 한계점\n",
    "\n",
    "품질 판정과 같은 프로젝트는 머신러닝 스킵하고 딥러닝이 가능. 프로젝트 진행 시에 완성하기 위한 스터디. 판다스는 for,if,dictionary,list\n",
    "\n",
    "lambda는 기본 문법 정확히 숙지시에 사용(서비스시 속도 개선)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MCBFVNbA8f9S"
   },
   "source": [
    "DT는 데이터의 디지털화, Digital Transformation or Digital Twin(실물을 가상으로 제작.ex)메타버스) 그 후에 simulation.\n",
    "\n",
    "스마트<->인공지능\n",
    "\n",
    "완전한 인공지능(인륜 배반 불가 기반)\n",
    "\n",
    "강인공지능-비지도학습(강화학습)\n",
    "약인공지능-지도학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vffIDQo29nCE"
   },
   "source": [
    "**커리시작**\n",
    "\n",
    "디지털 트랜스포메이션(DT) -본격 연구 시작 시기가 4년 전\n",
    "ex. 항공기나 자동차의 시운전\n",
    "\n",
    "직무에서 관련 데이터들을 분석하여 흐름과 결함을 찾아 보고하는 사회의 분위기.\n",
    "\n",
    "(digital twin을 내 캡디 프로젝트에? 사용하는 플랫폼?)\n",
    "\n",
    "digital twin에서의 요점 : domain 지식이 있어야 적용처를 찾을 수 있다.\n",
    "\n",
    "최근 일반적으로 3d를 사용해 DTwin을 생성, 전체 스마트 팩토리 시스템 도입 이전 Digital twin을 사용해 시험.\n",
    "\n",
    "디지털 트윈의 3가지 형태\n",
    "1. 관제 모델\n",
    "2. 운영 모델\n",
    "3. 최적화 모델\n",
    "\n",
    "데이터 분석이 공정 단계에서 관제 및 관리의 역할\n",
    "\n",
    "데이터 분석에서 판단은 머신러닝, 딥러닝의 분류모델을 사용\n",
    "\n",
    "분석가는 판단하지 않는다. 귀책사유!, 의견만.\n",
    "\n",
    "운영 모델은 관제 모델의 분석에 따라 직접 실행. 최적화 모델은 운영 모델의 목적에 따라 목적 달성을 위해 최적화\n",
    "\n",
    "관리자가(관제모델) 정시 원서 접수 받아야겠는데?\n",
    "운영모델(서버)이 가동, 최적화모델(학생)이 접수\n",
    "\n",
    "1. 빅데이터 분석에서 시각화기능 = 관제 모델, data stream을 통해 monitoring\n",
    "2. 빅데이터에서 운영모델 = 결과를 지속적으로 predict하는 model, 디지털 트윈에 파라미터를 설정해서 물리적대상을 제어가능. 조명이나 설비의 밸브를 원격 제어, 공조설비 제어로 실내 온도 조절\n",
    "\n",
    "3. 전처리단계 = 최적화 단계, 모델 최적화도 가능. \n",
    "\n",
    "*공공데이터를 가공(전처리)해서 파는 것이 가능 - 과제로도 가능\n",
    "\n",
    "디지털 스레드? 디지털 트윈의 정보를 하나로 연결해주는 기술, 파이썬의 파이프 개념. 모델들의 연결에 핵심적이다.\n",
    "\n",
    "**위 내용 잠시 접어둠**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4XVOu_daaTt4"
   },
   "source": [
    "**빅데이터 분석 이론 시작**\n",
    "\n",
    "데이터 수집>데이터 전처리>데이터 저장>데이터 분석\n",
    "\n",
    "데이터 분석에는 문제를 찾아내거나 많냐 적냐를 판단하는 분석 등등 종류가 다양(건보료 연령 문제)\n",
    "\n",
    "어떤 제작사, 배우, 각본가 조합이 가장 히트를 치는지? 부산에서 가장 아름다운 곳은? -> 감성분석으로 추천이 가능\n",
    "\n",
    "데이터를 수집할 수 있는지 없는지가 관건, 데이터 수집 시에 연/월/일/시 가 있는 것이 좋음.\n",
    "\n",
    "수집했다면 저장\n",
    "\n",
    "프로젝트 진행 시에 수집 전처리 분석 모델링 서비스 단계로 진행. 가장 많이 소요되는 기간이 있음. 수집 및 전처리 과정에서 엄청난 시간과 프로그래밍이 필요.\n",
    "\n",
    "개인적 노트북 추천 : 국산 노트북은 과열이 심하거나 버전 충돌 가능성이 있음.\n",
    "레노보가 가성비좋음, 델도 좋음.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XcOGrRdw9sI-"
   },
   "source": [
    "# 2023년 1월 3일 \n",
    "\n",
    "아나콘다 설치 후 첫 실행\n",
    "(기본 파이썬도 깔려있지 않은 환경에서)\n",
    "\n",
    "아나콘다 파워쉘 프롬프트를 관리자 권한으로 실행(주피터 노트북 킬때마다 이걸로 열기+웬만한 건 관리자 권한으로 키는 걸 추천)\n",
    "\n",
    "프롬프트에서\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LVdyDwhv_DWv"
   },
   "outputs": [],
   "source": [
    "cd /\n",
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9o--f1LI_HXm"
   },
   "source": [
    "입력하면 디렉토리 내부 파일 목록이 나열\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CZrxDPGX_E2W"
   },
   "outputs": [],
   "source": [
    "cd pu #작업 폴더로 현재 디렉토리 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hSzlgwFY_L9m"
   },
   "source": [
    "친 상태에서 탭누르면 자동으로 경로 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-ZOokEdrAhtj"
   },
   "outputs": [],
   "source": [
    "jupyter notebook #입력시 실행 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b_S4BvPJBb_X"
   },
   "source": [
    "마우스 왼쪽으로 클릭 시에 파워쉘프롬프트가 선택 관리자(상단 실행 프로그램 이름확인)가 되는데, 우클릭하여 그냥 관리자로 변경해줘야한다. 선택 관리자 모드에선 타이핑이 안된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ijnq5jMADaWW"
   },
   "source": [
    "종료시엔 파워쉘 프롬프트에서 crtl+c를 누를 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vnt_NCz9D1zF"
   },
   "source": [
    "주피터 노트북에서 new->python 3(ipykernel) 을 클릭하면 우리가 사용할 파일 생성 가능. 파일 이름 클릭해서 이름 변경 가능. 파일 탐색기에서와 마찬가지로 주피터에서도 파일 관리 가능. 폴더 생성시 (주피터에서 new-folder-rename 클릭)둘 중에 편한 방법을 고르면 된다. 주피터에선 드래그로 파일 이동이 불가. 탐색기에서 이동시켜야함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LSMtMvVMJKSN"
   },
   "source": [
    "주피터에서 셀 선택후 m을 누르고 #입력, 띄우고 텍스트를 적어넣으면 제목으로 설정 가능 ##이면 좀더 작아짐. #을 늘릴수록 작아진다.\n",
    "\n",
    "ctrl+enter로 셀 작성 완료 가능\n",
    "\n",
    "셀 선택후 dd 입력 or 가위 모양 클릭시 셀 삭제 가능\n",
    "\n",
    "수정은 더블 클릭\n",
    "\n",
    "shift+Enter로 넘기면 해당 셀 박스를 실행시키고 다음 셀박스를 자동 생성\n",
    "\n",
    "alt+Enter도 shift+Enter랑 비슷함. 하지만 alt+Enter는 맨 마지막에 셀을 생성. shift+Enter을 중간에서 입력하면 alt+Enter와 다르게 셀을 생성하지 않고 실행 후에 다음 셀로 이동만 함.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YnU8zq6_Nc6d"
   },
   "source": [
    "변수의 이름이 메모리 공간에 할당됨.\n",
    "\n",
    "특정 메모리의 값을 출력해주는 함수는 print()\n",
    "\n",
    "주피터노트북에선 변수 이름만 입력해도 해당 print()값을 출력해준다. 웬만하면 print()사용하기\n",
    "\n",
    "'#'기호로 주석처리 가능\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P-2KUlErRMxA"
   },
   "source": [
    "변수 개념 정리 (2교시), 2day_파이썬_기본 파일에 정리 중\n",
    "\n",
    "Error 발생시 무슨 유형의 오류(마지막 줄 or 첫 줄)인지, 가장 먼저 발생한 오류의 위치는 어디인지 확인하기.\n",
    "\n",
    "정수<>문자열 타입 변경 시 str()과 int() 함수의 사용\n",
    "\n",
    "연산자의 사용\n",
    "\n",
    "문자열에서 인덱스 개념\n",
    "\n",
    "비교연산자의 출력은 True(1), False(0)\n",
    "\n",
    "조건 연산자를 활용하여 조건문(선택문) 사용하기\n",
    "\n",
    "##<문제> 본인 주민번호 뒷자리 전체를 변수에 넣고 성별을 판별하세요\n",
    "\n",
    "첫번째 문제, 문자열에서 인덱스활용\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fLgAgRW0gXlB"
   },
   "source": [
    "print문에서 .format()을 활용한 출력\n",
    "\n",
    "format에서 중괄호 내부 인덱스를 활용가능\n",
    "\n",
    "연-월-일을 표현하고자 할 때 .format()을 많이 활용한다.\n",
    "\n",
    "**반복문**\n",
    "\n",
    "이 강의에서는 while문 보다는 for문을 많이 활용\n",
    "\n",
    "range(시작값, 끝값, 증가값)에서 생략가능한 값은 시작값, 증가값\n",
    "default값은 각각 0과 1이다.\n",
    "\n",
    "while은 뒷 조건이 맞기만 하면 무한반복\n",
    "\n",
    "##<문제>반복문에서 두번째 문제\n",
    "\n",
    "0부터 100까지 범위에서 짝수의 총합\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O9D21u9059d0"
   },
   "source": [
    "##<문제>빈 공간에 특정값 넣기(.zfill()의 활용)\n",
    "\n",
    "\"1\".zfill(n) #1이라는 문자열을 오른쪽으로 보내고 남은 자리를 0으로 채운다.\n",
    "얘도 날짜 표시에 많이 사용\n",
    "\n",
    "**3번째 문제**\n",
    "2010년 1월부터 2022년 12월까지의 짝수년-짝수월(0000-00)을 출력하기\n",
    "\n",
    "*강사님 첫번째 답안에서는 반복되며 if문을 계속 체크, 필요없는 홀수년도도 월을 체크함\n",
    "두번째 답안에서는 홀수년도는 for문을 스킵. continue를 사용하는게 부하가 덜하고 속도도 빠르다.*\n",
    "\n",
    "**4번재 문제**\n",
    "문자열을 하나하나 출력하기\n",
    "\n",
    ".replace(\" \",\"\") 첫번재 값과 같은 값을 모두 찾아서 두번째 값으로 변환\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IiyGSUd-EmtO"
   },
   "source": [
    "##데이터 처리시 사용하는 형식들\n",
    "\n",
    "여러개의 값을 담을 수 있는 형태\n",
    "\n",
    "n_list=[1,2,\"a\",\"ab\"]\n",
    "\n",
    "1 2 a ab 문자열과 동일한 방법으로 메모리 공간 사용. 하나의 공간에 하나의 변수.\n",
    "\n",
    "리스트에 항목을 추가하고 싶을 땐 .append() 함수를 사용\n",
    "\n",
    "n_list. 을 입력후 tab을 누르면 사용가능한 함수들이 출력됨.\n",
    "\n",
    "n_list. 을 입력후 shift+tab을 누르면 현재 변수의 타입과 length 등이 나온다.\n",
    "\n",
    "파이썬에서는 문자열을 object. 정수를 int, 소수를 float type을 사용한다. n_list.append 뒤에 shift+tab을 누르면 뭘 넣어야 하는지 알려준다.\n",
    "\n",
    "**문제 : 리스트 내부 항목 각각 출력하기**\n",
    "\n",
    "for i in n_list:\n",
    " print (i)\n",
    "로 사용함\n",
    "\n",
    "list 내부 개수를 파악해주는 함수가 존재. list의 길이를 알지 못할 때 for문에 사용 \n",
    "\n",
    "** for문을 사용하는 2가지 방식(리스트) 기억해두기**\n",
    "\n",
    "드래그 후 crtl+/ 를 하면 전체 주석처리 가능!\n",
    "\n",
    "리스트에서는 +,*가 사용가능하다.\n",
    "\n",
    "**문제 : 리스트 속 리스트를 다른 리스트에 옮기기!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "teVzZkhrImKF"
   },
   "source": [
    "##딕셔너리\n",
    "\n",
    "키와 밸류 값으로 이루어지는 딕셔너리의 메모리 구성은 어떻게 될까?\n",
    "\n",
    "person = {\"이름\":\"홍길동\",\"나이\":26}\n",
    "\n",
    "큰 박스의 메모리 구성. 콤마의 개수만큼 자르고, 콤마로 구분된 각각의 값들이 박스 내부에 ||이름|홍길동|||나이|26|| 이런 식으로 나뉜다.\n",
    "접근 시에는 key값으로 접근한다.\n",
    "\n",
    "값을 뽑을 때는 항상 대괄호를 사용한다.\n",
    "여기서도 person[\"이름\"]으로 접근\n",
    "결과값은 홍길동\n",
    "\n",
    "보통은 key를 정수 or 문자열 중 하나로 통일\n",
    "\n",
    "딕셔너리.keys()로 key값들을 뽑아낼 수 있다.\n",
    "딕셔너리.values()로 value값들도 뽑아낼 수 있다.\n",
    "딕셔너리.items()로 key,value들을 모두 튜플 형태로 가져올 수 있다.\n",
    "(튜플은 리스트로 해석해도 무방, 단지 생성시 변경 불가)\n",
    "\n",
    "**딕셔너리 문제**\n",
    "\n",
    "리스트 변수와 딕셔너리 변수가 주어지고 키값에 해당하는 value를 리스트로\n",
    "\n",
    "2차원 데이터 형태로 만들 때 해당 표현을 많이 쓴다!\n",
    "\n",
    "리스트는 추가할 때 append()를 활용\n",
    "변경할때는 인덱스 값을 활용\n",
    "\n",
    "딕셔너리는?\n",
    "리스트의 인덱스로 수정하듯 딕셔너리의 키로 원래 없던 값을 추가 가능하다. 있던 키를 넣으면 수정이 가능\n",
    "\n",
    "튜플은 리스트와 결이 같다.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lisjnmirpmvx"
   },
   "source": [
    "**함수**\n",
    "\n",
    "함수의 정의 방법\n",
    "\n",
    "def로 시작\n",
    "def 함수이름() : \n",
    "\n",
    "뽑아오겠다 하는 의미로는 get...의 이름을 많이 사용하고 저장하겠다 하는 의미로는 set...의 이름을 많이 사용함.\n",
    "\n",
    "()안에 함수가 받을 input을 정의\n",
    "return으로 함수가 계산한 output을 도출\n",
    "\n",
    "함수 내에서 기능이 많을 경우, 구분자가 필요.\n",
    "\n",
    "들여쓰기가 되어있는 영역 내에서만 변수 공유 가능 : 전역변수의 개념\n",
    "\n",
    "함수 정의 시에 매개변수들의 초기값을 설정할 수 있다. (입력 값을 받아 올 수 없다면 해당 값을 사용)\n",
    "\n",
    "**함수, 반복, 조건 활용 구구단 문제**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wiUsWmugzW1y"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pj8fiWiqEznO"
   },
   "source": [
    "# 2023년 1월 4일\n",
    "\n",
    "(조회 : 비대면 출석은 증빙 서류 제출이 가능한 경우에만!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "btrumnjTE3-G"
   },
   "source": [
    "**클래스**\n",
    "\n",
    "*개체나 그룹\n",
    "\n",
    "여러가지의 기능(함수)이나 제원(변수,사양)이 포함된다. 값을 정의해두지 않는다.\n",
    "\n",
    "java나 다른 프로그램들에서도 전부 class 생성시 대문자로 시작하자.\n",
    "\n",
    " (' : ' -> block을 만들겠다. 들여쓰기 되어있는 애들끼리! )\n",
    "\n",
    "함수 정의 시, 매개변수(파라미터) 사용\n",
    "\n",
    "클래스 정의 시에는 조금 다르다. 멤버 변수를 사용. 클래스 내부의 모든 함수를 사용하기 위해서 변수들의 첫번째 자리에 self라는 변수를 무조건 사용.\n",
    "\n",
    "클래스는 호출의 개념이 아니라 생성의 개념\n",
    "ex) 학교에 강의실이 있으려면 실제로 강의실을 만들어야한다. 강의실 개념에 속하는 607호와 601호를 만든다(클래스 생성). 학교 내부에 공간을 할당한 것. 공간 내부엔 기능들이 존재. 주피터 노트북에서 예시로 생성한 클래스에는 5개의 기능들이 존재함.\n",
    "\n",
    "클래스를 생성할 때 클래스 뒤에 ()가 붙는 것은 생성자. 강의실 클래스의 예시에서는 607호는 객체. mm은 클래스 변수라고 부르자. 클래스 변수를 print하면 클래스가 존재하는 주소가 나온다. \n",
    "\n",
    "멤버에 접근할 때는 ' . ' 을 사용. ' . '은 접근 지정자라고 한다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TBNPLHsOTIWN"
   },
   "source": [
    "**모듈**\n",
    "\n",
    "현재 하나의 파일에서 사용 중(함수, 클래스 등)\n",
    "\n",
    "모듈은 파일을 따로 저장해놓고 필요할때마다 불러들여서 사용하는 방법과 관련이 있다.\n",
    "\n",
    "__init__()은 생성자를 만들기 위해 사용해야 하는 파이썬 규칙\n",
    "\n",
    "값을 최초에 안 넘겨준다면 __init__이 없어도 된다. default로 존재\n",
    "\n",
    "__init__()내부엔 멤버 변수도 따로 정의해준다. 클래스에서 사용. 어디서든지 self.으로 접근해서 사용가능. \n",
    "\n",
    "받아온 값을 self.a와 self.b에 넣어준다면, 해당 class 내부에서 어디에서든지 이 변수들을 사용할 수 있다.p_a,p_b는 클래스 내부에서 사용하고 끝.\n",
    "\n",
    "ipynb는 주피터노트북에서만 사용하는 확장자명이다. 범용적으로 사용되는 .py로 바꿔줘야함.\n",
    "\n",
    "file-> save as-> 에서 py로 다운받고 사용할 파일과 같은 경로에 배치한다. \n",
    "\n",
    ".py로 만들어진 파일을 모듈이라고 한다.\n",
    "\n",
    "import 시에 as를 활용하여 별칭을 붙일 수 있다.\n",
    "\n",
    "생성만 시켜서 주소만 출력되면 안되니까 클래스 변수로 받아와야 한다. 여기서 클래스 변수는 util\n",
    "\n",
    "이 util을 활용하여 self로 정의된 것과 함수가 보여진다(멤버들이 모두 보여짐). 변수는 값을 바꿀 수 있고 함수는 호출이 가능.\n",
    "\n",
    "모듈은 클래스를 파일로 만들어놓고 사용하고자 하는 곳에서 불러들이기 위해 만든 편의성 개념이 강하다.\n",
    "\n",
    "기능은 클래스!\n",
    "\n",
    "module을 모아놓는 패키지가 존재.\n",
    "\n",
    "모듈 하나를 불러들일때는 import, 패키지를 사용할때는 from을 사용.\n",
    "\n",
    "py파일을 폴더에 넣은 뒤, 메모장으로 내용 확인\n",
    "\n",
    "폴더 단위 관리 = 패키지 관리\n",
    "\n",
    "예시에서 폴더이름은 utils 고 파일 이름은 fn_module이다. - from utils import fn_module\n",
    "\n",
    "폴더가 여러개일 경우, from 가장외부폴더.그다음폴더.그다음폴더. ... import 사용할 모듈로 사용한다!\n",
    "\n",
    "주피터에서 py파일은 수정은 되는데 실행은 안됨.\n",
    "\n",
    "**모두 동일한데 오류가 발생할때? 맨 위탭에서 Kernel->Restart를 누르면 메모리공간을 아예 초기화시킨다.**\n",
    "\n",
    "**파이썬 기초 특강 끝*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t9E8-OlVhxYB"
   },
   "source": [
    "https://url.kr/hq3bd1\n",
    "이게 수업 공유 구글 드라이브 링크\n",
    "\n",
    "kto는 관광객 입국에 대한 데이터\n",
    "\n",
    "데이터의 형태? \n",
    "1. 일반적인 데이터\n",
    "2. 일반적이지 않은 데이터\n",
    "\n",
    "엑셀은 가장 윗줄에 데이터 변수 혹은 Column, feature가 있다. 그 아래로는 변수에 해당하는 값들이 나열되어 있다. \n",
    "\n",
    "일반적으로 데이터 수집시 용량이 상당히 커지기 때문에 파일 하나하나 (일별,월별,연도별) 나뉘어져있는 경우가 많다.\n",
    "\n",
    "분석시엔 전체를 하나로 통합해서 사용해야한다. \n",
    "\n",
    "행데이터가 많다면 데이터의 건수가 많다->깊이가 깊음\n",
    "\n",
    "열데이터가 많다면 종류가 많아지고 column이 늘어난다. 이렇게 늘어나도 빅데이터에 포함.\n",
    "\n",
    "수집한거 하나만 쓰지않고, 원하는 데이터도 붙여서 작업\n",
    "\n",
    "기본적으로 데이터 작업에선 2차원 데이터를 가지고 작업-> 엑셀형태\n",
    "\n",
    "데이터 분석에서는 판다스 라이브러리가 제공하는 함수를 대부분 사용\n",
    "\n",
    "판다스 = function based program\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kp16lwKh83Rb"
   },
   "source": [
    "**01_데이터활용하기 ipynb 파일 작성시작**\n",
    "\n",
    "데이터를 불러들일 때 사용하는 방법이 있음\n",
    "\n",
    "명령 -> 데이터 형태로 가져와서 편하게 쓰기? -> 데이터 프레임(or table or 행렬 ...)\n",
    "\n",
    "pandas의 기능을 살펴보자.\n",
    "\n",
    "**엑셀파일 불러들이기**\n",
    "\n",
    " 엑셀 파일을 읽어 들일때는 read_excel() 함수 사용\n",
    " - 읽어들인 데이터의 형태는 데이터프레임 형태라고 칭합니다.\n",
    " - 데이터프레임 : 행과 열로 되어있는 형태\n",
    " - 1번째 값 : 파일위치 및 파일명\n",
    " - 2번째 header : 제목의 위치\n",
    " - 3번째 skipfooter : 제일 하단에 읽어들이지 않을 행을 지정\n",
    " - 4번째 usecolls : 읽어들일 변수(컬럼==제목)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uGb5bzvm-4tF"
   },
   "outputs": [],
   "source": [
    "# colab에선 실행 불가!\n",
    "pd.read_excel(\"./files/files_01/sample_1.xlsx\",\n",
    "             header = 1,\n",
    "             skipfooter = 2,\n",
    "             usecols = \"A:C\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AqePcNF0-7JJ"
   },
   "source": [
    "실행할때마다 아나콘다의 경로에 설치된 pandas를 탐색.\n",
    "\n",
    "프로그래밍 할 때 확장자에 따라 함수가 달라지므로 탐색기에서 확장자를 항상 표시하도록 설정해 둘 것!\n",
    "\n",
    "대제목과 통계 데이터가 들어있는 경우가 많다.\n",
    "불러들일 때 필요없는 건 모두 제외해야함.\n",
    "\n",
    "순수한 데이터의 부분만 불러들이는 게 정석이다. 대제목도 필요가 없음.\n",
    "\n",
    "받는 변수는 매개변수(속성)\n",
    "\n",
    "파일 예시 활용\n",
    "\n",
    "첫번째에 데이터를 대표하는 이름을 header,\n",
    "header를 1로 지정하면, 엑셀에서는 2번째 행\n",
    "(파이썬은 0부터 시작하므로 header는 1로)\n",
    "\n",
    "skipfooter는 제외할 것을 설정->제일 아래에서 부터 2개를 제외시킴.\n",
    "\n",
    "usecols는 가져올 column의 위치를 지정함. column은 범위를 나타낸다.(A, C, D)로 B만 빼고 가져올 수 도 있다.\n",
    "\n",
    "예시 엑셀에서는 A-2, C-8 범위를 지정\n",
    "\n",
    "보통 파이썬에서는 0번째 sheet를 선택하는게 default.\n",
    "\n",
    "header = 0 이라면? 기본값이므로 생략가능하다.\n",
    "아래 총합계와 전년동기가 없다면 제외할 게 없으므로 skipfooter도 생략가능. cols도 모두 가져올 것이라면 생략이 가능\n",
    "\n",
    "read_excel로 가져온 것(data frame)을 저장해야 한다. '변수에'(예시에선 sample_1)에 저장\n",
    "\\\n",
    "\\\n",
    "\\\n",
    "**데이터 프레임 변수 내부에 있는 정보를 확인하자**\n",
    "\n",
    ".info()를 통해 확인하면,\n",
    "<class 'pandas.core.frame.DataFrame'> 가 출력되는데, pandas~frame폴더 내부의 클래스임을 확인할 수 있다.\n",
    "\n",
    "\n",
    "다음줄 부터 해석하면, \n",
    "\n",
    "rangeIndex(행)는 전체 6개 각각 0부터 5까지 있다.\n",
    "데이터 변수(열)는 3개를 가지고 왔다. 컬럼도 인덱스 번호를 보유하고 있음. 컬럼 명 옆의 번호는 rangeindex의 개수. 빈 칸이 존재한다면 그 칸은 count하지 않는다. (예시에서는 null이 아닌 값이 6개라는 뜻). 그 뒤엔 data type을 표시\n",
    "\\\n",
    "\\\n",
    "\\\n",
    "range대비 각 column의 개수가 동일한지 확인해야한다! (이상치 처리). range 개수가 더 작다면 결측치가 존재하는 것. \n",
    "\\\n",
    "\\\n",
    "\\\n",
    "정수값과 문자값이 동시에 존재할 경우 Dtype은 무조건 object로 잡힌다. 숫자만 존재하는 col에서 Dtype이 object로 잡혔다면 결측치를 확인해야한다.\n",
    "\\\n",
    "\\\n",
    "\\\n",
    "**.info()에서 확인할 사항**\n",
    "\n",
    "- RangeIndex(전체 행의 개수)와 각 Column(컬럼)의 개수가 동일한지 확인\n",
    "\n",
    "- 동일하지 않다면 Column(컬럼)에 누락된 값이 있을 수 있음 --> 결측치)\n",
    "\n",
    "- Dtype(데이터 타입) 확인하기 -> 이해하기 어려운 타입으로 되어있는 경우 데이터 확인\n",
    "\n",
    "**.head()와 .tail()로 데이터의 대략적 파악**\n",
    "\\\n",
    "\\\n",
    "\\\n",
    "데이터가 너무 많은 경우에는 전부 볼 필요는 없다. 잘 나오는지, 어떻게 구성되어있는지 간단히 확인할 때는 .head()를 사용\n",
    "\n",
    "기본적으로 상위 5개 데이터를 조회시켜준다.\n",
    "\n",
    "예시에서 rangeindex는 0~5. 그럼 정말 5에서 끝났는지 확인해야함. .tail()함수 활용\n",
    "\\\n",
    "\\\n",
    "\\\n",
    "**기본적인 통계정보들을 .describe()로 알 수 있다**\n",
    "\n",
    "최대 최소값을 확인하여 기초적인 이상치를 확인할 수 있다.(크기를 상식적인 수준에서 비교할 수 있으므로 ex)나이 데이터가 200 or 음수로 출력되는 경우)\n",
    "\n",
    "##컬럼 단위로 데이터 추출하기\n",
    "\\\n",
    "\\\n",
    "\\\n",
    "데이터프레임 변수 뒤에 대괄호로 출력 가능!\n",
    "- ex)sample_1[\"국적코드\"]\n",
    "\n",
    "column 별 리스트는 각각 하나씩 생긴다!(2차원이 돼야함)\n",
    "따라서 2개 이상의 coulmn별 데이터를 확인하려면 \n",
    "sample_1[[\"국적코드\",\"성별\"]]과 같이 입력해야한다. sample_1[[\"국적코드\",\"성별\",\"입국객수\"]]도 마찬가지.\n",
    "\n",
    "데이터 변수에 컬럼을 추가할 수 있다.\n",
    "딕셔너리와 같이 없으면 추가, 있으면 수정\n",
    "\n",
    "전체 데이터 개수를 알아서 체크한 다음 column에 해당하는 값들을 일괄처리\n",
    "\n",
    "- sample_1[\"기준년월\"] = \"2022-10\"\n",
    "\n",
    "##행 단위로 데이터 추출하기\n",
    "\\\n",
    "\\\n",
    "\\\n",
    "\\\n",
    "'특정값만 가지는 행만 조회하라'라는 명령을 내릴 수 있다.\n",
    "\n",
    "- 성별이 '여자'인 행만 확인하기\n",
    "\n",
    "데이터 처리에선 조건문을 필터링이라고 한다.\n",
    "\n",
    "- sample_1[\"성별\"] == \"여성\"\n",
    "\n",
    "를 실행하면 True, False로 필터링시켜준다. 해당 정보를 변수에 담는다.\n",
    "\n",
    "- condition = sample_1[\"성별\"] == \"여성\"\n",
    "\n",
    "이 정보를 데이터프레임으로 넘겨서 true인 것만 알려달라고 하면 된다.\n",
    "\n",
    "- sample_1[condition == True]\n",
    "\n",
    "조건을 만족하는 것만 가져오는 것은 기본적으로 이렇게 조회한다.\n",
    "\n",
    "- sample_1[condition == False]\n",
    "\n",
    "로 변경시, 남자만 출력한다. condition이 False인 행만 출력하는 것!\n",
    "\n",
    "과정을 보여준 것이고 나중에 숙달이 된다면,\n",
    "\n",
    "- sample_1[(sample_1[\"성별\"] == \"여성\") == True]\n",
    "\n",
    "처럼 한 문장으로 줄일 수 있다.\n",
    "\\\n",
    "\\\n",
    "\\\n",
    "**문제 \"입국객수\"가 150000 이상인 데이터만 추출하기**\n",
    "\\\n",
    "\\\n",
    "\\\n",
    "**문제 \"성별\"이 남성이면서 \"입국객수\"가 150000 이상인 데이터만 추출하기**\n",
    "\\\n",
    "\\\n",
    "\\\n",
    "pandas에서는 and를 나타낼 때 기호 &, or를 나타낼 때 기호 |를 사용한다.\n",
    "\\\n",
    "\\\n",
    "\\\n",
    "*(주피터 노트북 only)코드 작성하다가 너무 길어지는 경우, 줄바꿈을 하며 작성해야 하는데 comma가 있는 부분에서는 가능하고 comma가 없다면 \\표시를 하나 넣고 띄우지말고 바로 enter를 누르면 줄바꿈이 허용이 된다! 들여쓰기 가능*\n",
    "\\\n",
    "\\\n",
    "\\\n",
    "조건이 너무 길어짐을 대비해 함축한 기능이 있다. isin()이라는 함수가 있다.\n",
    "\\\n",
    "\\\n",
    "\\\n",
    "**.isin()함수의 사용**\n",
    "\\\n",
    "\\\n",
    "\\\n",
    "sample_1[\"국적코드\"].isin([\"A01\",\"A18\",\"A31\"])\n",
    "에서 인덱스를 하나하나 isin()내부의 항목과 일치하는지 검사하며 확인하며 True or False를 반환\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N3YqorFgUGra"
   },
   "source": [
    "\n",
    "**데이터 통합하기**\n",
    "\n",
    "다른 파일에 있는 정보를 가져와서 붙인다. \n",
    "\\\n",
    "\\\n",
    "\\\n",
    "***컬럼 단위로 통합***\\\n",
    "첫번째로 column 기준으로 붙이기, 현재 국적코드에 대한 국적명은 모르는 상태\n",
    "\\\n",
    "\\\n",
    "\\\n",
    "merge()함수의 사용\n",
    " 컬럼 단위로 통합하기 : merge()함수 사용\n",
    " - left : 통합할 기준 데이터 프레임\n",
    " - right : 가져올 데이터가 있는 데이터 프레임\n",
    " - how : 어떻게 가져올지 지정 (inner : 같은 것만, left : 왼쪽 전체, 없으면 없는대로)\n",
    " - left_on : 왼쪽 데이터프레임에서 오른쪽 데이터프레임과 비교할 컬럼 지정\n",
    " - right_on : 오른쪽 데이터프레임에서 왼쪽 데이터프레임과 비교할 컬럼 지정 -->\n",
    "\n",
    "데이터가 무분별하게 손실되는 것을 막고 싶다면 how의 inner 대신 left라고 명시해야 한다. 없으면 없는대로 NaN(null값)이라고 표시하고 데이터를 살려두기 때문.\\\n",
    "\\\n",
    "\\\n",
    "***행 단위로 통합*** \\\n",
    "\\\n",
    "\\\n",
    "행단위로 추가되는 데이터는 Column의 개수가 같아야한다.\n",
    "\\\n",
    "\\\n",
    "**concat()함수의 활용**\n",
    "\\\n",
    "\\\n",
    "리스트의 형태를 입력받으므로 여러개의 데이터를 합칠 수 있다.\n",
    "\\\n",
    "\\\n",
    "인덱스 관련해서 지정해주지 않으면 합치기 전 데이터들의 인덱스를 그대로 가져온다. ignoreindex값을 True로 설정한다(default가 False이다).\n",
    "\\\n",
    "\\\n",
    "데이터 전처리가 끝날때마다 저장을 해야한다. 주피터를 그냥 꺼버리면 그대로 메모리에 저장된 변수값이 날아가버림...\n",
    "\\\n",
    "\\\n",
    "\\\n",
    "**파일로 저장하기**\n",
    "\\\n",
    "\\\n",
    "\\\n",
    "load-save 과정 중에 no directory 에러는 경로를 찾지 못하거나 파일 이름이 잘못됐을 때 많이 나는 오류이다. 주의하기!\n",
    "\\\n",
    "\\\n",
    "\\\n",
    "가급적 데이터 프레임명과 파일명을 일치시켜주는 것이 좋다! -> 파일관리에 용이\n",
    "\\\n",
    "\\\n",
    "데이터프레임명.to_excel(\"디렉토리\",index = False)\n",
    "\\\n",
    "로 저장한다!\n",
    "\\\n",
    "\\\n",
    "파일 탐색기에서 ctrl+a로 엑셀파일 전체 선택후 맨 위 파일만 이름을 sample(0)정도로 바꿔주면 알아서 나머지 파일들의 이름이 숫자로 정렬된다!\n",
    "\\\n",
    "\\\n",
    "for문으로 함수를 만들어 여러 파일들을 합치기!\n",
    "\\\n",
    "\\\n",
    "concat()시에 오류가 날 수 있다.\n",
    "\n",
    " files_all의 모든 데이터 통합하기\n",
    " 최종 결과 변수명 : sample_all\n",
    " 최종 결과 파일명 : sample_all.xlsx\n",
    " 파일 저장위치 : files_01_new 폴더에...\n",
    " 기준 년도 : 2019-01 부터 시작합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "70AHEnbO6jn8"
   },
   "source": [
    "**데이터 통합 문제**\n",
    "\n",
    "데이터 변수는 절대 변경 불가\n",
    "\n",
    "concat이 완료된 시점까지는 오류가 나도 데이터는 합쳐진다.\n",
    "\n",
    "try: 와 except:문 (예외처리)\n",
    "\n",
    "오류(문법적 오류가 아니라 파일을 찾거나 하는 등의 물리적 오류)가 발생할 수 있는 부분에 try:를 넣고 오류가 발생하면 except: 부분으로 넘어간다. 강사님 답안에서는 pass로 오류가 발생해도 그냥 실행되도록 하였다.\n",
    "\\\n",
    "\\\n",
    "\\\n",
    "문제에서 바뀌는 변수가 2가지 있다면 for문을 2개 사용하여 중첩 반복문을 만들자! 아니면 수학적으로 가야돼서 너무 힘들다...\n",
    "\\\n",
    "\\\n",
    "\\\n",
    "웬만하면 한 줄씩 결과값 확인하면서 가자(print를 활용)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sR_wqrGE9hRk"
   },
   "source": [
    "#2023년 1월 5일"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QqZC9iJv9mct"
   },
   "source": [
    "파일이름이 제각각이라면 파일패턴을 만들어야 한다. 데이터 분석시에 파일명도 상당히 중요하다. 여러개가 있다면 일단 반복. 반복할 수 있는 패턴을 찾아야 한다.\\\n",
    "\\\n",
    "\\\n",
    "files_02 내부 파일은 kto_까지는 같으나 연월 순으로 패턴이 있다. 기준연월에 대한 데이터를 파일명에서 얻을 수 있음.\\\n",
    "\\\n",
    "\\\n",
    "파일 내부 확인(상용=비즈니스), 교포는 따로 입출국 목적을 두지 않는다고 한다.\\\n",
    "\\\n",
    "우리가 사용할 column = 관광, 상용, ... , 계 까지\\\n",
    "\\\n",
    "\\\n",
    "현재 파일이 어떤 시기의 데이터파일인지 알고 있어야 한다. 내부의 대제목에 있지만 거기서 뽑기는 쉽지 않다.\n",
    "\\\n",
    "\\\n",
    "데이터 분석시에 시기는 항상 있으면 좋다. 찾아보고 없으면 못 쓰는것.\\\n",
    "\\\n",
    "특정 코드에 대한 한글 명으로 된 것 -> 메타데이터(마스터코드, 마스터데이터)\\\n",
    "\\\n",
    "처리 끝나고 항상 저장하기!\\\n",
    "\\\n",
    "file read할 때는 대제목 처리 header, 하단 부분 처리 skipfooter, column범위 지장 usecols 속성을 조절하여 읽어들인다.\n",
    "\\\n",
    "\\\n",
    "info()와 describe()를 사용하여 정보와 간단한 결측치 확인이 가능\n",
    "\\\n",
    "상위 5개 확인 -> head(), 하위 5개 확인 - > tail()\n",
    "\\\n",
    "\\\n",
    "\\\n",
    "해당 excel에는 '주'가 먼저 나오고 그 주에 속하는 국가이름이 나오는 형식으로 정리돼있다.\n",
    "\\\n",
    "\\\n",
    "깨끗한 데이터프레임 만들기 : pd.DataFrame() <-pd 파일 내의 클래스를 생성하는 것\n",
    "\\\n",
    "\\\n",
    "\\\n",
    "**문제 각 컬럼에서 0인 데이터가 있는 부분만 필터링 하기**\n",
    "\\\n",
    "\\\n",
    "column기준으로 값 비교해서 True False 도출 하는 건\n",
    "\\\n",
    "`condition = (kto_201901[\"관광\"] == 0) | (kto_201901[\"상용\"] == 0) |\n",
    "            (kto_201901[\"공용\"] == 0) | (kto_201901[\"유학/연수\"] == 0) `\n",
    "\\\n",
    "로 한다!\n",
    "\\\n",
    "\\\n",
    "`kto_201901[condition == True]`\n",
    "\\\n",
    "를 그다음으로 입력하면 True가 있는 행들만 나온다!\n",
    "\\\n",
    "\\\n",
    "행이나 열의 데이터 값이 0이 너무 많다면? 계속 사용할지 고려해야함.\n",
    "\\\n",
    "\\\n",
    "(교포는 정책상 관광목적에서 그냥 기타로 분류->0이 많은 이유를 찾음->결측치는 아님)\n",
    "\\\n",
    "\\\n",
    "\"기준년월\"의 column이 추가 되어야 데이터만 보고 날짜 확인이 가능\n",
    "\\\n",
    "\\\n",
    "현재 데이터에서 대륙이름과 국가이름이 있음. 대륙이름을 필터링한 다음 버릴 수도 있고 쓸 수 도 있다.->쓰려면 대륙이름의 column을 만든다음 붙이면 될 것 같다!\n",
    "\\\n",
    "\\\n",
    "**대륙을 걸러내보자(필터링)**\n",
    "\\\n",
    "\\\n",
    "(주피터 노트북에서 텍스트 입력용 셀을 코드 셀로 바꾸려면 yy입력하면 됨)\n",
    "\\\n",
    "\\\n",
    "고유한 값들이 얼마나 있는지 확인한다.\n",
    "\\\n",
    "`.unique()`\n",
    "\\\n",
    "를 사용\n",
    "\\\n",
    "수작업으로 대륙이름 복사하면서 확인. 리스트를 직접 생성한 다음, 리스트에 포함되는 국적이 있는지 대조하는 과정을 거쳐야 한다. 있다면 True, 없다면 False가 되도록\n",
    "\\\n",
    "\\\n",
    "`kto_201901[\"국적\"].isin(continents_list)`\n",
    "를 거치면 \"국적\"column에 속하는 값들이 list와 비교되며 속하면 True, 없으면 False를 반환한다. 이를 condition으로 삼고 True가 되는 행만 출력시킨다면, `kto_201901[condition]`을 입력하면 되고, 아닌 값들을 저장하려면 `condition == False` 로 바꿔주면 된다.\n",
    "\\\n",
    "\\\n",
    "**지금 하는 작업은 정제**\n",
    "\\\n",
    "\\\n",
    "빠진 부분에 대한 index가 사라져있다!\n",
    "\\\n",
    "\\\n",
    "데이터프레임이 너무 길다면 .head(n)으로 확인\n",
    "\\\n",
    "\\\n",
    "인덱스 번호를 다시 0부터 재배열하는게 깔끔하다.\n",
    "\\\n",
    "\\\n",
    "reset_index()를 활용하면 인덱스 재배열이 가능\n",
    "\\\n",
    "\\\n",
    "속성 drop=True로 지정하면 기존 인덱스를 컬럼으로 올리지 않겠다고 할 수 있다.\n",
    " - drop = True : 기존의 인덱스 번호 사용하지 않을 때 사용(컬럼으로 만들지 않기)\n",
    " - drop = False : 기존의 인덱스 번호 사용할 때 컬럼으로 만듭니다.\n",
    " \\\n",
    " \\\n",
    "속성값은 잘 생각이 나지 않으면 그냥 찾아서 쓰면 된다. 외우지는 말기(좋긴 함)\n",
    "\\\n",
    "\\\n",
    "각 국가에 대륙이름을 맵핑 시키고 싶다?-> column으로 만들어야 한다. 국가마다 자동으로 맵핑시키려면? \n",
    "\\\n",
    "\\\n",
    "먼저 각각에 맞는 대륙이름 60개를 리스트에 쭉 넣을 것-> 문자열의 * 사용\n",
    "\\\n",
    "\\\n",
    "각 대륙이름 밑에 국가가 몇개 있는지 확인하면 된다. 대륙이름이 좀 옛날 이름이라서 다시 정의.\n",
    "\\\n",
    "\\\n",
    "리스트로 만들어서 컬럼에 넣어주면 자동으로 맵핑되며 합쳐진다.\n",
    "\\\n",
    "\\\n",
    "**각 국가별 관광객 비율이 보고 싶다.**\n",
    "\\\n",
    "\\\n",
    "어떻게 뽑아야 될까?\n",
    "\\\n",
    "\\\n",
    "관광객 비율을 계산하는 공식을 작성한뒤 컬럼을 추가해보자.\n",
    "`(kto_201901_country_newindex[\"관광\"])/(kto_201901_country_newindex[\"계\"])*100`\n",
    "으로 column끼리의 계산이 가능하다.\n",
    "\\\n",
    "\\\n",
    "**소수점을 좀 자르고 싶을 때 round()라는 함수가 있다!**<<모든 프로그램에서 다 나옴!\n",
    "\\\n",
    "\\\n",
    "소수점 1자리 까지 뽑고 싶다면 round(자르고싶은숫자,원하는 소수점 자리수)\n",
    "\\\n",
    "\\\n",
    "관광객 비율이 높은 순으로 정렬하고 싶을 때, sort_values(by = \"원하는 기준 컬럼\",ascending=False)를 사용.\n",
    "\\\n",
    "\\\n",
    "ascending은 오름차순을 의미(default)\n",
    "ascending을 false로 설정하면 내림차순!\n",
    "\\\n",
    "\\\n",
    "**대륙별 관광객 비율의 평균을 구해보자**\n",
    "\\\n",
    "\\\n",
    "pivot_table() 함수의 사용, (그룹을 짓는다는 의미)\n",
    "\\\n",
    "\\\n",
    " 집계 함수 : pivot_table() 함수 사용\n",
    " - 대륙별 관광객 비율(%)의 평균 집계하기\n",
    " - values : 집계할 데이터 지정\n",
    " - index : 집계 기준\n",
    " - aggfunc : 어떻게 집계할 것인지 함수 이름 지정\n",
    "\\\n",
    "\\\n",
    "pivot_table의 출력은 데이터프레임 형태는 아니다.\n",
    "\\\n",
    "\\\n",
    "**전체 국가 관광객 대비 관광객 비율**\n",
    "\\\n",
    "\\\n",
    "sort_values()에서 by 는 생략이 가능하다\n",
    "\\\n",
    "\\\n",
    "통합할 땐 조회관련 함수는 안해도 됨.\n",
    "대륙 걸러내기, 대륙 추가, 컬럼 추가(평균 등)\n",
    "\\\n",
    "\\\n",
    "파일 116개를 한번에 합치는 방법."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3wV7YMPmWAQf"
   },
   "source": [
    "####모든 파일 통합하기\n",
    "\\\n",
    "\\\n",
    "파일명의 규칙만 알고, 불러들인 이후부턴 하나의 데이터 프레임 관리처럼 하면 된다.\n",
    "\\\n",
    "\\\n",
    "\\\n",
    "resetindex는 마지막에 재정렬 해줘야 된다.\\\n",
    "판다스 라이브러리는 .reset_index를 함수내에서 실행하지 않으면 0번째 index가 없기에 0번째 index끼리 합쳐지지 않는다. ->경고 발생함.\n",
    "\\\n",
    "\\\n",
    "\\\n",
    "파일 읽어오기 부터 마지막 column추가 부분까지 함수로 지정한다.\n",
    "\\\n",
    "\\\n",
    "\\\n",
    "첫 실행시에 데이터 프레임을 초기화 시켜주지 않으면 데이터 프레임에 계속 합쳐질 수 있다!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FgIjrb1fWEpD"
   },
   "source": [
    "#### 데이터 시각화하기\n",
    "\\\n",
    "\\\n",
    "**kto_total.xlsx 파일을 사용하여 시각화 한다.**\n",
    "\\\n",
    "\\\n",
    "**그림을 그리는 시각화를 하려면 다른 라이브러리도 있어야 한다. `matplotlib`**\n",
    "\\\n",
    "\\\n",
    "그래프에 한글이 들어가는 경우가 있음. 영문으로 쓰는 경우는 괜찮지만 한글을 쓰는 경우에는 깨질 수 가 있다. font 지정을 하기 위한 라이브러리도 따로 필요.\n",
    "\\\n",
    "`from matplot lib import font_manager`\n",
    "\\\n",
    "`import platform`<-운영체제 체크\n",
    "\\\n",
    "가 있으면 된다.\n",
    "\\\n",
    "\\\n",
    "\\\n",
    "**한글을 처리**하는 방법은 굉장히 많으나 그 중 하나를 선택한다면,\n",
    "\\\n",
    "`plt.rc(\"font\", family = \"Mallgun Gothic\")`(윈도우용)\n",
    "\\\n",
    "를 사용한다.\n",
    "\\\n",
    "\\\n",
    "**음수 기호**를 사용하려면\n",
    "\\\n",
    "`plt.rcParams['axes.unicode_minus'] = False`\n",
    "\\\n",
    "로 설정한다. 안하면 깨진다.\n",
    "\\\n",
    "\\\n",
    "plt.rc 지정이 안돼있으면 한글이 ㅁ으로 보임(깨짐)!\n",
    "\\\n",
    "\\\n",
    "**중국 데이터만 불러와 시각화 해보자**\n",
    "\\\n",
    "\\\n",
    "plt.plot(x축값,y축값) - 선그래프\n",
    "\\\n",
    "\\\n",
    "그래프가 좀 예쁘진않음. x축 데이터도 보이지 않는다.\n",
    "\\\n",
    "\\\n",
    "**그래프를 디자인 한다.**\n",
    "\\\n",
    "\\\n",
    "`plt.figure(figsize=(20,4))`\n",
    "\\\n",
    "로 너비,높이 순으로 그래프 크기를 설정할 수 있다.\n",
    "\\\n",
    "\\\n",
    "`plt.title(\"제목\")`\n",
    "\\\n",
    "`plt.xlabel(\"x축이름\")`\n",
    "\\\n",
    "`plt.ylabel(\"y축이름:)`\n",
    "\\\n",
    "\\\n",
    "x축이 너무 촘촘해서 보이지 않는다. 범위를 지정한다.\n",
    "\\\n",
    "`plt.xticks([\"2010-01\",\"2011-01\",\"2012-01\",\"2013-01\",\"2014-01\",\n",
    "           \"2015-01\",\"2016-01\",\"2017-01\",\"2018-01\",\"2019-01\"])`\n",
    "\\\n",
    "예시에선 매년 1월 기준으로 나눈다. 해당 함수에 사용되는 값은 실제로 존재해야 사용할 수 있다.\n",
    "\\\n",
    "\\\n",
    "**### 우리나라에 방문하는 외국인 관광객이 가장 많은 국가 순으로 top5 조회하기**\n",
    "\\\n",
    "\\\n",
    "집계에서 기준값으로 많이 쓰는건 평균이다.\n",
    "\\\n",
    "\\\n",
    "pivot_table() 사용하기!\n",
    "\\\n",
    "\\\n",
    "pivot_table()의 출력은 dataframe 형태가 아니다.\n",
    "\\\n",
    "\\\n",
    "`temp.reset_index(inplace = True)`\n",
    "\\\n",
    "을 거치면 자동으로 데이터프레임으로 바뀐다.\n",
    "\\\n",
    "inplace 속성이 False가 되면, temp가 피봇테이블의 출력 상태 그대로 유지된다. inplace는 메모리에 자동 저장하는 기능이다. 변경된 것을 모두 반영시키는 것. resetindex에서 풀리는게 자동 저장된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yAFUXNqSD0aU"
   },
   "source": [
    "# 2023년 1월 6일"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ARMcNfHD15e"
   },
   "source": [
    "전 날 한건 데이터셋 116개를 처리. 최종적으로 통합하여 파일을 생성함. \n",
    "\\\n",
    "\\\n",
    "정상적인 증감과 비정상적 증감이 존재.\n",
    "\\\n",
    "\\\n",
    "국가별 하나씩 그리기\n",
    "\\\n",
    "\\\n",
    "주피터 노트북을 껐다가 키면 저장된 메모리의 값들이 모두 사라지므로 Kernel-restart & runall 탭을 이용한다.\n",
    "\\\n",
    "\\\n",
    "데이터 형태에선 튜플 형태를 시리즈라고 명칭한다. 시리즈는 인덱스 번호를 가지고 있다. 시리즈는 수직, 튜플은 수평적. 리스트와 활용방법이 똑같다.\n",
    "\\\n",
    "\\\n",
    "반복문에서 index번호를 이용하는 방법은 range()가 들어가야 한다!\n",
    "\\\n",
    "\\\n",
    "그래프에서 확인할 수 있는 추이가 매년 비슷하다면 -> 이슈가 많이 없다.\n",
    "\\\n",
    "중국의 경우에 2015년 6월과 2017년 초중반에 이슈가 있었던 것을 확인할 수 있다.\n",
    "\\\n",
    "일본에서도 2015년 중순쯤에 관광객이 많이 줄었다. 대만도!\n",
    "\\\n",
    "\\\n",
    "미국은 추이가 계속 비슷하다.(다른 대륙)\n",
    "\\\n",
    "\\\n",
    "아시아권인 홍콩은 다른 아시아권인 중국 일본과 비슷하게 2015년 중순에 관광객이 많이 감소했다.\n",
    "\\\n",
    "\\\n",
    "**->2015년 중순, 아시아권에 어떤 이슈가 있지 않았을까??**\n",
    "\\\n",
    "(구글링->메르스)\n",
    "\\\n",
    "\\\n",
    "연도및 월별 입국 관광객수를 확인하려면 3가지 데이터를 포함해서 자세히 봐야하는데, 이를 **히트맵**이라고 한다.\n",
    "\\\n",
    "\\\n",
    "그래프 이름이 소주제를 나타낸다.\n",
    "\\\n",
    "\\\n",
    "**년도 및 월에 대한 컬럼 추가하기**\n",
    "\\\n",
    "\\\n",
    "1.직접 접근(`df[\"기준년월\"]`에 접근)  \n",
    "해당 인덱스 번호로 접근  \n",
    "대괄호로 접근\n",
    "\\\n",
    "\\\n",
    "`df[\"기준년월\"][0]`는 문자열 형태\n",
    "\\\n",
    "문자열도 리스트와 같이 볼 수 있다. 문자열의 문자 하나하나에 접근할 수 있다.\n",
    "\\\n",
    "`df[\"기준년월\"][0][1]` <이렇게\n",
    "\\\n",
    "`df[\"기준년월\"][0][0:4]` 기준년월의 첫번째 값에서 연도만 추출할 수 있다.\n",
    "\\\n",
    "\\\n",
    "컬럼에 대입할 때 리스트형식으로 대입하면 가장 좋다.\n",
    "\\\n",
    "\\\n",
    "인덱스와 값 모두 사용가능하나, 여기선 인덱스 번호를 사용한 for문으로 접근하겠다.\n",
    "\\\n",
    "\\\n",
    "list에 값을 더하는 함수->append()\n",
    "\\\n",
    "\\\n",
    "2.문자열의 slice()를 사용한다.  \n",
    "이렇게 하면 for문 없이 단 2문장만으로 컬럼을 추가할 수 있다!\n",
    "\\\n",
    "\\\n",
    "\\\n",
    "이렇게 추가한 후에 시각화를 시켜보자\n",
    "\\\n",
    "\\\n",
    "**히트맵을 만들 때, 피봇테이블 형태의 데이터가 있어야 시각화가 편하다**\n",
    "\\\n",
    "\\\n",
    "피봇테이블 형태로 행에 월별 데이터, 열에 연도별 데이터를 만들 수 있는데, value값, index, column에 들어갈 column의 이름을 정해주기만 하면 된다.\n",
    "\\\n",
    "\\\n",
    "\\\n",
    "aggfunc=mean이 default다. 근데 여기서는 중국의 데이터가 연도-월별 하나뿐이므로 의미x\n",
    "\\\n",
    "\\\n",
    "행쪽이 index y축, 컬럼으로 나오는 건 x축, 찍는 값은 value, (aggfunc=mean 이면 평균으로 찍는다. 여기선 의미x)\n",
    "\\\n",
    "\\\n",
    "보이는 네모 상자가 히트맵. 이걸 그림으로 표현이 가능하다.\n",
    "\\\n",
    "\\\n",
    "2015년 6월쯤 중국인 관광객 수가 떨어지기 시작해서 7월에 최소치를 보인다!\n",
    "\\\n",
    "\\\n",
    "2017년 3월쯤 떨어지기 시작해서 4월에 완전히 떨어진다.\n",
    "\\\n",
    "\\\n",
    "히트맵도 matplotlib에 들어있긴 하나 seaborn에 들어있다..\n",
    "\\\n",
    "\\\n",
    "히트맵을 사용할 때는\\\n",
    "`sns.heatmap(df_pivot, annot = True, fmt = \".0f\", cmap = \"rocket_r\")`\n",
    "\\\n",
    "로 히트맵 그래프 함수에 데이터를 넣을 수 있고  그래프 크기 지정이나 그래프 제목, 보여주는 건 plt 라이브러리를 사용한다.\n",
    "\\\n",
    "\\\n",
    "히트맵이라는 함수가 알아서 피봇에 대한 형태를 그대로 분리시킨 다음 x축, y축, 들어가는 데이터를 뽑아서 출력시켜준다.\n",
    "\\\n",
    "\\\n",
    "annot이라는 속성은 숫자값을 보여줄 것인지 말 것인지 설정, fmt = \".0f\"는 정수는 정수대로, float는 float대로 보겠다는 것, cmap은 히트맵의 색깔을 설정할 수 있다. 이건 검색하면 찾기 쉬움!\n",
    "\\\n",
    "\\\n",
    "2015년 6월에는 메르스, 2017년 2월에는 사드보복 문제가 있었던 걸 히트맵을 확인하여 알 수 있다.\n",
    "\\\n",
    "\\\n",
    "이 분석을 insight 분석이라고 한다!\n",
    "\\\n",
    "\\\n",
    "**입국객 관련 데이터 분석 끝**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SJmelF6zDh4S"
   },
   "source": [
    "데이터를 하나 받으면 주제를 뽑고 각 주제에 맞게 그래프를 2-3개씩 뽑아내면 된다. 주제는 3-4개 정도 혹은 전부 뽑아내도 된다. \n",
    "\\\n",
    "국가 교통 데이터 오픈 마켓(포항시 BIS 교통카드 사용내역)\n",
    "\\\n",
    "\\\n",
    "에서 받은 것.\n",
    "\\\n",
    "\\\n",
    "포항시 관련 공공 데이터\n",
    "(www.diamond-e.kr)\n",
    "\\\n",
    "판매 업체에 데이터 관련 문의를 하고 업데이트 일자를 보고 언제까지 데이터가 있는지 확인하기\n",
    "\\\n",
    "\\\n",
    "제공 포맷/압축 포맷을 확인\n",
    "\\\n",
    "\\\n",
    "제공방식도 확인. 제공하는 방식이 파일 형식이냐 api방식이냐 2가지가 있음. api방식은 프로그램에 api링크를 만든 다음 사용. 파일은 말그대로 다운로드.\n",
    "\\\n",
    "\\\n",
    "column 명이 영어로 되어있는데, 이 경우엔 meatadata가 존재. metadata파일은 영문 명이 뜻하는 의미를 제공해준다.\n",
    "\\\n",
    "\\\n",
    "sample data도 확인\n",
    "\\\n",
    "\\\n",
    "정부기관, 공공기관 데이터를 사용할 때는 로그인이 필수\n",
    "\\\n",
    "\\\n",
    "구매하기 버튼을 누르면 선택하여 구매하는 창이 뜬다.\n",
    "\\\n",
    "\\\n",
    "데이터 활용시 목적을 물어보면 '연구'라고 작성하면 된다.\n",
    "\\\n",
    "\\\n",
    "현재 첫번째 컬럼과 두번째 컬럼은 16진수로 나온다.\n",
    "\\\n",
    "\\\n",
    "csv파일을 메모장으로 연결하여 open\n",
    "\\\n",
    "\\\n",
    "이러면 엑셀파일에서 16진수로 보였던게 다시 숫자로 보임. 얘는 엑셀이 아니라 텍스트 파일. csv는 특수문자로 구분해서 텍스트파일로 저장하는 형식. 파일을 줄이면서 가볍게 사용하고자 할 때 csv 형식을 사용한다. \n",
    "\\\n",
    "\\\n",
    "txt파일을 써도 되나, 특수문자로 구분하는 포맷이 csv!\n",
    "\\\n",
    "\\\n",
    "excel은 65526개의 용량 한계가 있다. 용량도 좀 커진다.\n",
    "\\\n",
    "\\\n",
    "tfcard 내부를 확인해보면 콤마로 구분되어있고 줄이 끝나는 곳은 콤마가 없다. 콤마가 끝나기 전까지 하나의 데이터\n",
    "\\\n",
    "\\\n",
    "연,월,일 하나씩 하나의 데이터. 받을때 똑같은 이름으로 되어있어서 받고 난 다음 라벨링을 해줘야 한다. 폴더 단위로 있으면 불편하다. 코드 마스터는 똑같으므로 하나만 있으면 됨.파일명은 똑같고 폴더명만 다름.\n",
    "\\\n",
    "\\\n",
    "총 합치면 버스 이용량 관련 분석이 3가지. 전처리 과정이 좀 빡셈.\n",
    "\\\n",
    "\\\n",
    "\\\n",
    "생각할만한 주제?\n",
    "1. 연령별 버스 이용 거리\n",
    "2. 시기별 버스 이용 거리(요일 or 월 or 연도)\n",
    "3. 버스 이용거리 or 양\n",
    "\\\n",
    "\\\n",
    "제시된 주제\n",
    "[소주제 3]\n",
    "<시간대별 버스 이용량 분석>\n",
    "-기준월 및 기준일자별 버스 이용량 분석 비교\n",
    "-기준일 및 시간대별 버스 이용량 분석 비교\n",
    "-기준시간 및 시간(분)별 버스 이용량 분석 비교\n",
    "\n",
    "<버스 내 체류시간 분석>\n",
    "-기준일 및 시간대별 버스내 체류시간(분) 분석 비교\n",
    "-시간 및 승객 구분별 빈도 분석 비교\n",
    "\n",
    "<승하차 정류장별 버스 내 체류시간 분석>\n",
    "-승하차 정류장별 체류시간(분) 상위 30건 분석 비교\n",
    "\\\n",
    "\\\n",
    "**데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TBg0hwgl11Ib"
   },
   "source": [
    "#2023년 1월 9일 (2주차)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aOdLwMi416GN"
   },
   "source": [
    "전처리->DB->웹->머신러닝->딥러닝 예정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "viTvH9tj2MzI"
   },
   "source": [
    "### 가상환경 생성하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xb8P8M9r2qFB"
   },
   "source": [
    "프롬프트를 처음 열면 base가 나온다. 하다가 base가 깨지면 골치아픔. 가상환경은 디렉토리 위치 상관x. 주피터 노트북을 열때 가상환경 위치에 따라 열림. 생성시는 상관없다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X8qe0ET23Ouv"
   },
   "source": [
    "자신이 사용하는 드라이브로 먼저 경로 설정.\\\n",
    "\\\n",
    "c:\n",
    "\\\n",
    "\\\n",
    "*버전 체크하기\\\n",
    "-파이썬 버전 확인 :`python --version`\n",
    "\\\n",
    "-아나콘다 버전 확인 :`conda --version`\n",
    "\\\n",
    "\\\n",
    "*가상환경 목록 확인하기\\\n",
    "`conda env list`\n",
    "\\\n",
    "\\\n",
    "base의 위치와 생성할 가상환경의 위치는 조금 다르다. base는 가상환경과 달리 envs 아래에 없다.\n",
    "\\\n",
    "\\\n",
    "*버전 업그레이드 하기\\\n",
    "-`conda update -n base conda`\n",
    "\\\n",
    "가상공간 이름이 n인 base conda를 업데이트 하라\\\n",
    "-이건 자주 업데이트 해줘도 된다.\n",
    "\\\n",
    "\\\n",
    "-`python -m pip install --upgrade pip`\n",
    "\\\n",
    "pip로 인스톨된 모듈을 업그레이드 하라는 뜻.\\\n",
    "\\\n",
    "\\\n",
    "-`conda update --all`\n",
    "\\\n",
    "콘다 전체 업데이트\n",
    "\\\n",
    "\\\n",
    "conda나 pip업그레이드는 종종해주는게 좋다.\n",
    "\\\n",
    "\\\n",
    "*가상환경 생성하기\n",
    "\\\n",
    "`conda create -n 가상 환경 이름 python = 3.9`\n",
    "\\\n",
    "`conda create -n pknu_base python = 3.9`\n",
    "\\\n",
    "\\\n",
    "가상환경 목록을 확인해서 실제 생성됐는지 체크\n",
    "\\\n",
    "`conda env list`\n",
    "\\\n",
    "\\\n",
    "*가상환경 삭제하기\n",
    "\\\n",
    "`conda env remove -n 가상환경이름 `\n",
    "\\\n",
    "\\\n",
    "*가상환경 활성화하기\n",
    "\\\n",
    "`conda activate 가상환경이름`\n",
    "\\\n",
    "`conda activate pknu_base`\n",
    "\\\n",
    "\\\n",
    "*설치 목록(패키지) 확인하기\n",
    "\\\n",
    "`conda list`\n",
    "\\\n",
    "`pip list`\n",
    "\\\n",
    "내 가상환경에 설치된 목록들을 확인한것\n",
    "\\\n",
    "conda list는 아나콘다가 직접 설치.(자체적)\n",
    "\\\n",
    "pip list는 pip(범용,콘다가 찾지 못한다면)\n",
    "\\\n",
    "\\\n",
    "주피터 노트북 탐색기에서 new를 눌렀을 때, 가상환경 이름이 나와야 가상환경을 사용할 수 있다. 혹은 아예 주피터 노트북이 안들어가질 수 있음.\n",
    "\\\n",
    "\\\n",
    "*가상공간에 패키지 설치하기\n",
    "`conda install -c conda-forge jupyter notebook`\n",
    "\\\n",
    "\\\n",
    "*가상공간을 주피터 노트북과 연결하기\n",
    "\\\n",
    "`python -m ipykernel install --user --name 가상환경이름 --display-name 보여질 이름`\n",
    "\\\n",
    "`python -m ipykernel install --user --name pknu_base --display-name pknu_base_kernel`\n",
    "\\\n",
    "\\\n",
    "아나콘다의 가상공간과 주피터의 공간(웹환경)을 연결한다라는 개념이 들어감.->kernel(이름은 바꿔도 상관이 없다)\n",
    "\\\n",
    "\\\n",
    "*커널 목록 확인하기\n",
    "`jupyter kernelspec list`\n",
    "\\\n",
    "\\(커널 설치는 주피터를 통해서 한다.)\n",
    "\\\n",
    "\\\n",
    "가상환경 이름이 나오면 커널이 설치되어있다는 뜻.\n",
    "\\\n",
    "\\\n",
    "*커널 삭제하기\n",
    "\\\n",
    "`jupyter kernelspec uninstall pknu_base`\n",
    "\\\n",
    "\\\n",
    "`jupyter kernelspec uninstall 가상환경이름`\n",
    "\\\n",
    "\\\n",
    "이제 pknu_base_kernel이 new탭에 있다. 가상공간이름을 바꿔주고 싶다면, kernel 메뉴-change kernel에서 base,pknu등의 커널 중에 하나를 선택.\n",
    "\\\n",
    "\\\n",
    "항상 현재 사용하고 있는 가상환경이 무엇인지, not trust를 선택해서 trust로 바꿔준다.\n",
    "\\\n",
    "\\\n",
    "*기본 패키지 설치하기\n",
    "\\\n",
    "\\\n",
    "`pip install ipython jupyter matplotlib pandas sklearn xlrd seaborn`\n",
    "\\\n",
    "\\\n",
    "`pip install openpyxl`\n",
    "\\\n",
    "\\\n",
    "(pip install 명령어 뿐만 아니라 conda install 명령어로도 가능함)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PVbUUm0HHHiC"
   },
   "source": [
    "### 6day 시작\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GQTpoUQhHMBR"
   },
   "source": [
    "드라이브만 정해서 바로 작업시작(주피터 노트북 실행)\n",
    "\\\n",
    "\\\n",
    "판다스 데이터 구조 이해\n",
    "\\\n",
    "\\\n",
    "**시리즈**\n",
    "\\\n",
    "인덱스 번호와 데이터, 하지만 컬럼명은 없는 구조\n",
    "\\\n",
    "인덱스 번호로 접근이 가능하다.\n",
    "\\\n",
    "\\\n",
    "데이터프레임에서 컬럼의 한줄 한줄이 series 형태\n",
    "\\\n",
    "\\\n",
    "딕셔너리에서는 왼쪽의 key가 index, 오른쪽 값이 data가 된다.\n",
    "\\\n",
    "\\\n",
    "`sd = pd.Series(dict_data)`로 자동으로 딕셔너리->시리즈로 변환\n",
    "\\\n",
    "\\\n",
    "그냥 시리즈에 리스트만 데이터로 주어도 인덱스가 이미 존재하기 때문에 시리즈로 자동 변환이 된다.\n",
    "\\\n",
    "\\\n",
    "튜플의 인덱스 번호를 시리즈에 자동으로 대입해서 변환\n",
    "\\\n",
    "\\\n",
    "**데이터 프레임 생성하기**\n",
    "\\\n",
    "\\\n",
    "딕셔너리에서 key가 컬럼, value값들이 컬럼아래 들어가는 data(리스트)\n",
    "\\\n",
    "\\\n",
    "예시에서는 2열 5행의 데이터프레임이 만들어진다.\n",
    "\\\n",
    "\\\n",
    "리스트로 만들 땐 2차원으로 만들어야 한다.\n",
    "\\\n",
    "\\\n",
    "리스트 별 같은 인덱스의 데이터 끼리 같은 column으로 들어간다.\n",
    "\\\n",
    "\\\n",
    "column명은 columns의 속성을 이용해서 넣는다.\n",
    "\\\n",
    "\\\n",
    "컬럼명은 리스트로 만들어서 변수만 넣으면 됨.\n",
    "\\\n",
    "\\\n",
    "리스트에 들어가는 각각의 값들을 for문에 대입하면 전체 리스트에 대입하기만 하면 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LD0T8s8RR4kB"
   },
   "source": [
    "**데이터 프레임 조작**\n",
    "\\\n",
    "\\\n",
    "load_dataset은 내장돼있는 데이터셋을 읽어들일때 사용한다.\n",
    "\\\n",
    "\\\n",
    "`tips[:]`\n",
    "\\\n",
    "를 type하면 전체 데이터를 조회\n",
    "\\\n",
    "\\\n",
    "행렬은 모두 index번호가 존재. 보여줄 때는 인덱스 값으로 표현.\n",
    "\\\n",
    "\\\n",
    " 2번 인덱스 삭제하기\n",
    "`tips.drop([2])`\n",
    "\\\n",
    "\\\n",
    "(데이터 분석시 원본은 절대 건드리지 말고 따로 저장해서 사용)\n",
    "\\\n",
    "\\\n",
    "2번인덱스를 삭제하고 나서의 `tips_del`에서 3번 인덱스로 보이는 행은 인덱스 번호는 2번, 인덱스 값은 3\n",
    "\\\n",
    "\\\n",
    "`tips_del.iloc[2]`으로 접근하면 2번째 인덱스는 있어서 값을 보여주지만 \n",
    "\\\n",
    "`tips_del.loc[2]`로 접근하면 삭제한 행의 인덱스 value이기 때문에 에러가 발생한다.\n",
    "\\\n",
    "\\\n",
    "마지막 행만 조회하기\n",
    "`tips_del.iloc[-1]`\n",
    "\\\n",
    "\\\n",
    "인덱스 값을 이용해서 특정행 조회하기\n",
    "`tips_del.loc[[0, 1, 3]]`\n",
    "\\\n",
    "\\\n",
    "특정 컬럼에 직접 접근하려면 loc or iloc를 사용하여야 한다. 그냥 `tips_del[0:3]`으로 접근하면 경고가 뜸.\n",
    "\\\n",
    "\\\n",
    "loc에서 [0:3]이면 0부터 3번 인덱스값 모두 조회. 없으면 없는대로\n",
    "\\\n",
    "\\\n",
    "iloc에서는 인덱스 자체를 사용하기때문에 range와 비슷하다고 보면 된다. 0부터 3보다 1작은 2까지의 인덱스 번호를 이용하여 행조회\n",
    "\\\n",
    "\\\n",
    "`dataframe.loc[행,컬럼]`\n",
    "\\\n",
    "\\\n",
    "인덱스 번호 범위를 다룰 땐 항상 +1 감안하기!\n",
    "\\\n",
    "\\\n",
    "loc와 iloc관련 연습하기!\n",
    "\\\n",
    "\\\n",
    "특정 값 하나를 체크하는 메소드도 존재.\\\n",
    "`tips.iat[1, 1]`\\\n",
    "(편의상 iat[1,1]을 잘 사용하지 않는다. iloc를 계속 사용)\n",
    "\\\n",
    "\\\n",
    "변수 자체의 type확인은 .dtype, 데이터프레임 자체의 type확인은 type()\n",
    "\\\n",
    "\\\n",
    "`tips.total_bill`\n",
    "\\\n",
    "`tips[\"total_bill\"]`\n",
    "\\\n",
    "둘다 같은 컬럼에 대한 같은 접근법이다.\n",
    "\\\n",
    "\\\n",
    "일반 변수의 형 변환은 int(),str()등을 사용했지만 데이터 프레임 형태의 변환은 astype()을 사용한다.\n",
    "\\\n",
    "\\\n",
    "데이터 프레임에서 구분 가능한 데이터들을 범주형 데이터-> category. 일반적으로 문자열.\n",
    "\\\n",
    "\\\n",
    "데이터 프레임이 load될 때, 파이썬 라이브러리가 만들어낸 type이 있음. 정수만 있다면 int, 문자열만 있다면 object 등\n",
    "\\\n",
    "\\\n",
    "`tips[\"smoker\"].astype(str)`\n",
    "\\\n",
    "으로 바꾸고 보여주는 것을 다시 저장시켜줘야한다.\n",
    "\\\n",
    "`tips[\"smoker\"] = tips[\"smoker\"].astype(str)`\n",
    "\\\n",
    "을 입력해야 수정이 되는 것.\n",
    "\\\n",
    "\\\n",
    "**데이터 각 컬럼의 갯수 확인하기**\n",
    "\\\n",
    "\\\n",
    "`데이터프레임.count()`\n",
    "를 사용한다.\n",
    "\\\n",
    "\\\n",
    "일반적으로는 `len()을 많이 사용`\n",
    "\\\n",
    "\\\n",
    "인덱스 범위를 이용해서 카운트 가능\n",
    "\\\n",
    "`len(tips.index)`\n",
    "\\\n",
    "tips.index는 RangeIndex라는 타입의 데이터를 출력한다.\n",
    "\\\n",
    "\\\n",
    "**컬럼 이름 조회하기**\n",
    "\\\n",
    "`tips.columns`를 입력하면 리스트 형태로 이름들을 출력\n",
    "\\\n",
    "\\\n",
    "각 컬럼에 들어있는 값만 뽑을 수도 있다\n",
    "\\\n",
    "`tips.values`\n",
    "\\\n",
    "(일반적으로는 loc, iloc로 접근, 쟝고의 프레임웍에서 이 방식을 사용(이름으로 접근))\n",
    "\\\n",
    "\\\n",
    "특정 컬럼의 데이터만 조회하고 싶을 때\n",
    "\\\n",
    "`tips[\"tip\"].values`\n",
    "\\\n",
    "\\\n",
    "데이터프레임.sort_values( , , ,)는 데이터들을 사용해서 정렬\n",
    "\\\n",
    "데이터프레임.sort_index( , ,)는 인덱스 번호를 기준으로 정렬할 때 사용\n",
    "\\\n",
    "\\\n",
    "`axis = 1`로 두면, 열단위로 정렬. tips에서 실행 시 column의 순서가 abcd순으로 정렬된다(문자열이므로)\n",
    "\\\n",
    "\\\n",
    "sort_index에서 컬럼 기준 정렬은 되지만, sort_values에서 컬럼 기준 정렬은 불가.\n",
    "\\\n",
    "\\\n",
    "**데이터 통합하기(행 / 열)**\n",
    "\\\n",
    "\\\n",
    "concat에서 axis 속성이 default로 0이다. 이때, axis = 1로 설정해주면, 행단위(아래)로 합치는게 아니라 열단위(옆으)로 합칠 수 있게 한다.\n",
    "\\\n",
    "\\\n",
    "데이터 옆으로 통합하기 (조건 들어감)\n",
    "\\\n",
    "inner : 두 개 데이터 프레임에서 같은 조건에 대해서만 가져오기\n",
    "\\\n",
    "`pd.merge(df_info1, df_info2, how = \"inner\")`\n",
    "\\\n",
    "\\\n",
    " 데이터프레임의 왼쪽을 기준으로 모든 데이터 가져오고,\n",
    "                오른쪽을 기준으로 모든 데이터 가져오기..\n",
    "\\\n",
    "`pd.merge(df_info1, df_info2, how = \"outer\")`\n",
    "\\\n",
    "\\\n",
    "왼쪽을 기준으로 같으면 같은대로 없으면 없는대로 가져오기\n",
    "\\\n",
    "`pd.merge(df_info1, df_info2, how = \"left\")`\n",
    "\\\n",
    "같은 column이 없다면 on을 명시해야 한다.\n",
    "\\\n",
    "\\\n",
    "`pd.merge(df_info1, df_info2, how = \"right\")`\n",
    "\\\n",
    "얘는 많이 안쓰긴 함.\n",
    "\\\n",
    "\\\n",
    "집에서 하려면 usb에 작업디렉토리 통째로 복사해서 옮겨놓고 아나콘다 설치해서 하면 됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bau1CrHTJGfL"
   },
   "source": [
    "### 03_빈도_교차분석 시작\n",
    "\\\n",
    "\\\n",
    "**빈도 분석**\n",
    "\\\n",
    "특정 컬럼 지정 후, `value_counts()`를 하면 카테고리별 카운트를 실시한다. ->그래프로 그리면 빈도표\n",
    "\\\n",
    "\\\n",
    "**교차 빈도 표**\n",
    "\\\n",
    "`pd.crosstab(tips[\"sex\"], tips[\"day\"])`\n",
    "\\\n",
    "\\\n",
    "`.crosstab( , , margins = True)`로 하면 '합계'를 볼 수 있다.\n",
    "\\\n",
    "\\\n",
    "람다는 단축형 프로그램이다. 간단한 로직을 빠르게 처리하거나 반복을 하는데 있어서 편리함\n",
    "\\\n",
    "\\\n",
    "**퍼센트로 나타내기**\n",
    "\\\n",
    "`pd.crosstab(tips[\"sex\"], tips[\"day\"]).apply(\n",
    "                lambda r: r/len(tips), axis = 1\n",
    ")`\n",
    "\\\n",
    "r이 데이터들을 하나씩 받으며 len(tips)(=전체 갯수)로 나눈 값을 다시 넣는다.\n",
    "\\\n",
    "\\\n",
    "crosstab의 출력물이 dataframe형태가 아니므로 lambda를 사용하지 않으면 퍼센트로 나타내는 것이 번거로워진다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9i_u7rIkMPA0"
   },
   "source": [
    "### 결측치 처리하기 시작"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R82mMTx4MSFr"
   },
   "source": [
    " - 전처리 : 결측치 데이터, 중복데이터, 이상치 데이터 처리\n",
    " - 결측치 : 특정 컬럼에 값이 없는 경우 어떻게 처리할 것인지\n",
    " - 중복 : 행들의 값들이 중복된 경우 어덯게 처리할 것인지\n",
    " - 이상치 : 특정 범위를 벗어나는 값들에 대해 어떻게 처리할 것인지\n",
    " - -> 일반적인 처리는 : 삭제, 값채우기 방식을 주로 사용..\n",
    " - -> 이상치 처리의 경우에만, 이상치 산출 계산공식을 사용하여 처리\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DAbllUkQODSr"
   },
   "source": [
    "**결측치**\n",
    "\\\n",
    "ex) 100개 중 하나의 데이터에서 성별란이 비어있다? 해당 index를 삭제하고 분석하느냐(100개 중에 하나이고 데이터를 확인할 수 없으므로), 많은 비율의 성별을 넣고 분석하느냐는 분석가의 선택\n",
    "\\\n",
    "\\\n",
    "성별란이 1개 대신 50개가 비어있다면?\n",
    "\\\n",
    "1. 분석 포기\n",
    "2. 비율대로 채워 넣기\n",
    "3. 해당하는 모든 행을 삭제\n",
    "\\\n",
    "\\\n",
    "보통 1,2를 선택."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D2NtIkZTOrtS"
   },
   "source": [
    "**중복**\n",
    "\\\n",
    "중복데이터가 있다면 중복데이터는 모두 제거해야함. 중복이 맞긴한데 제거하지 않으면? 같은 값의 빈도가 계속 높아진다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "un8esmicPDxZ"
   },
   "source": [
    "**이상치**\n",
    "\\\n",
    "\\\n",
    "데이터의 분포를 보았을 때, 혼자 떨어져있는 데이터와 모여있는 데이터가 있다. 너무 벗어나 있는 데이터를 계산으로 찾아내야 하고, 분석에 영향을 미친다면 제거해야 한다.\n",
    "\\\n",
    "이상치인 데이터마저 필요한 상황이라면 유형을 파악한 후에 값을 바꿔 활용한다.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8r_76zxGRRkZ"
   },
   "source": [
    "*판다스에서 읽어들이는 기본 포맷은 utf-8(표준 프로토콜)이다. 기본적으로 utf-8로 파일을 받았다면 메모장으로 열어서 다른이름으로 저장했을때, 인코딩에 utf-8이 되어있어야 한다.*\n",
    "\\\n",
    "\\\n",
    "한글이 들어있는 경우 깨지는 경우가 많다.\n",
    "\\\n",
    "\\\n",
    "`df = pd.read_csv(file_path, encoding = \"euc-kr\")`\n",
    "\\\n",
    "\\\n",
    "이렇게 읽어들이면 깨지지 않는다. euc-kr은 한국 공식 포맷"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NwNXglt-YUWB"
   },
   "source": [
    "**결측치 확인하는 함수**\n",
    "\\\n",
    "\\\n",
    "`.isnull()`\n",
    "\\\n",
    "\\\n",
    "**결측치가 아닌 것만 확인하는 함수**\n",
    "\\\n",
    "\\\n",
    "`.notnull()`\n",
    "\\\n",
    "\\\n",
    "각 컬럼별 결측치가 있는 갯수 확인하기\n",
    "\\\n",
    "sum(0) : 0의 의미는 행단위로 갯수 sum하기..\n",
    "\\\n",
    "`df.isnull().sum(0)`\n",
    "\\\n",
    "행 단위로 결측 데이터 컬럼의 갯수 확인하기\n",
    "\\- sum(1) : 1의 의미는 컬럼의 갯수를 의미함\n",
    "`df.isnull().sum(1)`\n",
    "\\\n",
    "\\\n",
    "결측치가 있는 행을 모두 삭제하기\n",
    "행단위 삭제 : axis=0\n",
    "\\\n",
    "`df.dropna(axis=0)`\n",
    "\\\n",
    "결측치가 있는 컬럼 삭제하기\n",
    "컬럼 단위 삭제하기 : axis = 1\n",
    "\\\n",
    "컬럼 단위 삭제는 데이터를 통째로 날리는 거라 잘 하지 않는다.\n",
    "\\\n",
    "\\\n",
    "여러개 컬럼을 기준으로 행단위 삭제하기\n",
    "\\\n",
    "`df[[\"대여소번호\",\"대여거치대\",\"이용시간\"]].dropna()`\n",
    "\\\n",
    "\\\n",
    "dropna()속 생략된 속성은 axis=0\n",
    "\\\n",
    "\\\n",
    "삭제를 하면 데이터 개수가 줄어든다.\n",
    "\\\n",
    "\\\n",
    "**결측치 처리 -> 채우기**\n",
    "\\\n",
    "\\\n",
    "`df.fillna(0)`\n",
    "\\\n",
    "을 사용하면 결측치 부분을 모두 0으로 채울 수 있다. 0부분을 문자열로 바꾸면 모두 문자열로 채울 수 있다.\n",
    "\\\n",
    "\\\n",
    "`df[\"이용거리\"].fillna(df[\"이용거리\"].mean())`\n",
    "\\\n",
    "로 하면 평균으로 채울 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ATkubpDeeJ1i"
   },
   "source": [
    "**중복 데이터 처리**\n",
    "\\\n",
    "\\\n",
    "`df[df.duplicated()]`\n",
    "\\\n",
    "이걸 입력했을 때, 출력 데이터프레임이 없다면 중복데이터가 하나도 없다는 뜻!\n",
    "\\\n",
    "\\\n",
    "중복되는 값들 중 두번째 등장하는 값들부터 .duplicated()의 출력이 True가 된다.\n",
    "\\\n",
    "\\\n",
    "중복 데이터 처리 방법 지정 : keep 속성 사용\n",
    "\\\n",
    "first : 첫번재 중복데이터는 살리고(false), 나머지 true\n",
    "\\\n",
    "last : 마지막 중복데이터는 살리고(false), 위에 나머지 true\n",
    "\\\n",
    "`df.duplicated([\"이용거리\"], keep = \"first\")`\n",
    "\\\n",
    "\\\n",
    "중복이 있는 모든 데이터 삭제하기\n",
    "\\\n",
    "`df.drop_duplicates([\"이용거리\"], keep = False)`\n",
    "\\\n",
    "(많이 쓰이는 기능은 아니다!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0jSnk9edk9e5"
   },
   "source": [
    "# 2023년 1월 10일"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zYK3v6kklHqh"
   },
   "source": [
    "**이상치 데이터 확인하기**\n",
    "\\\n",
    "\\\n",
    "**시각화로 먼저 확인**\n",
    "\\\n",
    "\\\n",
    "박스플롯 그리기\n",
    "\\\n",
    "\\\n",
    "박스플롯에서 4분위수 및 통계량에 대한 이해\n",
    "\\\n",
    "\\\n",
    "최소 이상치, 최대 이상치(outlier) 경계선. 이 선을 벗어나면 outlier이상치로 취급. 최소 경계선은 Q1-1.5x(Q3-Q1)로 구할 수 있고, 최대 경계선은 Q3+1.5x(Q3-Q1)으로 구할 수 있다.\n",
    "\\\n",
    "\\\n",
    "예시의 박스플롯에서 최소이상치는 없다는 것을 확인\n",
    "\\\n",
    "\\\n",
    "q1=1분위수, q3=3분위수는 describe로 확인하거나 numpy에서 제공하는 함수로 확인할 수 있다.\n",
    "\\\n",
    "\\\n",
    "넘파이 함수를 이용해서 특정 퍼센트에 해당하는 시점의 데이터 확인하기\n",
    "\\\n",
    "`q1, q3 = np.percentile(df_drop_allrow[\"나이\"],[25,75])`\n",
    "\\\n",
    "`print(\"q1=\",q1,\"/ q3=\",q3)`\n",
    "\\\n",
    "\\\n",
    "\\\n",
    "코드 선택 후 괄호를 입력하면 선택한 코드들을 둘러싸는 괄호를 생성가능!\n",
    "\\\n",
    "\\\n",
    "**데이터프레임과 확인하고자하는 컬럼명을 넘겨주면 outlier를 출력해주는 함수 만들기**\n",
    "\\\n",
    "\\\n",
    "일정 수준 이상의 outlier들까지 제거하느냐, 포함하느냐 선택.\n",
    "\\\n",
    "\\\n",
    "outlier들의 인덱스 번호를 알면 그 행들을 제거할 수 있다.\n",
    "\\\n",
    "\\\n",
    "numpy의 함수 중에 oo조건만 만족하는 index값만 뽑을 수 있는 기능을 가진 것이 있다.\n",
    "\\\n",
    "\\\n",
    " **필터링 조건에 만족하는 인덱스 값만 추출하는 함수 사용**\n",
    "\\\n",
    "\\\n",
    "  where() : 넘파이 함수, 배열로 리턴해 줍니다.\n",
    "\\\n",
    "\\\n",
    "  넘파이 배열과 파이썬의 리스트 차이점\n",
    "\\\n",
    "    : 파이썬의 리스트 : 여러 타입의 데이터값 넣을 수 있음\n",
    "\\\n",
    "    : 넘파이의 배열   : 한 가지 타입의 데이터값만 넣을 수 있음\n",
    "\\\n",
    "    : 위 차이점 외에 리스트와 사용법 및 기호가 모두 동일\n",
    "\\\n",
    "`np.where(((df_drop_allrow[\"나이\"]>=lower_bound)\\\n",
    "                &(df_drop_allrow[\"나이\"]<=upper_bound))==False)`\n",
    "\\\n",
    "\\\n",
    "np.where()의 출력은 튜플의 형태이다.\n",
    "\\\n",
    "\\\n",
    "출력된 array의 값들이 인덱스 번호인지 인덱스 값인지 확인\n",
    "\\\n",
    "\\\n",
    "값을 재배열했기 때문에 인덱스 값과 번호가 같은 상황이다. ->>loc와 iloc의 조회결과가 같음\n",
    "\\\n",
    "\\\n",
    "age_outlier_index에 해당하지 않는 인덱스번호를 거르면 된다.\n",
    "\\\n",
    "\\\n",
    "하나하나 확인하려면 전체프레임 길이 만큼 확인하면서 특정 index가 있다면 담지 않고, 없으면 담으면 된다. 정상 데이터프레임을 새로 만드는 것.\n",
    "\\\n",
    "\\\n",
    "데이터프레임.index를 사용하면 Rangeindex()의 형태 데이터가 출력된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5yUXzqCBygka"
   },
   "source": [
    "깨끗한 데이터프레임 변수 : \n",
    "\\\n",
    "age_non_outlier_index\n",
    "\\\n",
    " 전체 데이터프레임에서 이상치 10개를 제외하고..\n",
    "\\\n",
    " 깨끗한 데이터프레임에 담기\n",
    "\\\n",
    " 총 10건을 제외한 348건이 나오면 정상\n",
    " \\\n",
    " \\\n",
    "아닌 조건(포함되어 있지 않다면) : not in\n",
    "\\\n",
    "포함되어 있다면 : in\n",
    "\\\n",
    "\\\n",
    "데이터프레임.loc[i]를 하면 세로로, 데이터프레임.loc[[i]]를 입력하면 횡으로 해당 행이 출력된다!\n",
    "\\\n",
    "\\\n",
    "**2차원으로 만들어야 데이터프레임 형태로 만들어 출력되니 주의**\n",
    "\\\n",
    "\\\n",
    "리스트에 인덱스 값을 append해서 제거하는 방식도 있다!\n",
    "\\\n",
    "\\\n",
    "**drop 함수를 이용해서 이상치 제거하기**\n",
    "\\\n",
    "`df_new = df_drop_allrow.drop(age_outlier_index[0])`\n",
    "\\\n",
    "\\\n",
    "속도는 이게 더 빠름!\n",
    "\\\n",
    "\\\n",
    "for문에선 ignoreindex를 했기 때문에 인덱스 번호가 초기화.\n",
    "\\\n",
    "drop을 사용하면 .reset_index사용해서 index를 초기화 시켜주자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n2PD3QbtEdq6"
   },
   "source": [
    "**데이터 탐색_그룹 재구조화**\n",
    "\\\n",
    "\\\n",
    "class별 그룹화 하기...\n",
    "\\\n",
    "`df1 = df.groupby([\"class\"])`\n",
    "\\\n",
    "\\\n",
    "df1의 각 class별 인덱스번호가 부여된다.\n",
    "\\\n",
    " A반 그룹에서 0,1,2,3번, B반 그룹에서 0,1,2,3번, C반 그룹에서 0,1번. df1.head(1)로 조회하면 각 그룹의 0번 인덱스들이 출력되고, (2)를 넣으면 각 그룹에서 2명씩, (3)도 마찬가지다.\n",
    "\\\n",
    "\\\n",
    "**특정 그룹 조회하기**\n",
    "\\\n",
    "`df1.get_group(\"A\")`\n",
    "\\\n",
    "\\\n",
    "**특정 컬럼을 기준으로 그룹화 한 후 그룹들의 평균을 구하기**\n",
    "\\\n",
    "데이터프레임 내에 숫자 컬럼들에 대해서만 평균을 계산합니다.\n",
    "\\\n",
    "그룹의 기준이 되는 컬럼은 행으로..\n",
    "\\\n",
    "나머지 숫자 데이터를 가지는 컬럼들은 열로 표현됨\n",
    "\\\n",
    "`.groupby(\"class\").mean()`\n",
    "\\\n",
    "\\\n",
    "그룹화하는 컬럼의 기준이 2개라면, (ex)반과 성별 동시에 그룹화 시켰다면 그룹은 A반 남자,A반 여자, B반 남자, B반 여자, ... 로 나뉘어진다.\n",
    "\\\n",
    "\\\n",
    "`df_temp.mean()`으로 확인이 가능\n",
    "\\\n",
    "\\\n",
    "데이터 프레임에서 컬럼을 이용해서 지정하는 방식에서, 컬럼을 지정하는 방식은 다양하다.\n",
    "\\\n",
    "\\\n",
    "(방법1) 클래스 그룹별 수학점수의 평균 구하기\n",
    "\\\n",
    "`df.groupby(\"class\")[\"math\"].mean()`\n",
    "\\\n",
    "\\\n",
    "(방법2) 클래스 그룹별 수학점수의 평균 구하기\n",
    "\\\n",
    "`df[\"math\"].groupby(df[\"class\"]).mean()`\n",
    "\\\n",
    "\\\n",
    "(방법3)\n",
    "\\\n",
    "`df.groupby([\"class\"]).mean()[\"math\"]`\n",
    "\\\n",
    "\\\n",
    "결과는 모두 같다. 순서대로 해석하면 됨.\n",
    "\\\n",
    "(방법3)의 경우는 df에서 class를 기준으로 그룹을 짓고, math에 대한 평균을 낼 것이다.\\\n",
    "<<같은 방식(mean()까지만 입력하면 데이터 프레임의 형태. 거기서 math컬럼만 조회한것)\n",
    "\\\n",
    "\\\n",
    "반별로 수학 응시생의 수를 조회해 주세요...\n",
    "\\\n",
    "`df.groupby([\"class\"]).count()[\"math\"]` \n",
    "\\\n",
    "혹은\n",
    "\\\n",
    "`df.groupby([\"class\"])[\"math\"].count()`\n",
    "\\\n",
    "\\\n",
    "**데이터 프레임으로 출력**하려면??\n",
    "\\\n",
    "\\\n",
    "`[\"math\"]`부분을 2차원으로 하면, 즉,`[[\"math\"]]`으로 만들면 데이터프레임 형태로 출력된다!\n",
    "\\\n",
    "\\\n",
    "성별 수학점수 최고점 출력하기\n",
    "\\\n",
    "\\\n",
    "`df.groupby([\"sex\"])[[\"math\"]].max()`\n",
    "\\\n",
    "\\\n",
    "**그룹의 내부구조 확인하기**\n",
    "\\\n",
    "`sex_group.groups`\n",
    "\\\n",
    "\\\n",
    "<문제>위 groups의 형태를 이용해서...\n",
    "m에 있는 모든 인덱스값을 추출해서 하나씩 출력해주세요..\n",
    "\\\n",
    "\\\n",
    "내 답안\n",
    "\\\n",
    "`for i in sex_group.groups['m']:\n",
    "    print(i)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SfAaPuWlUdsp"
   },
   "source": [
    "**데이터 재구조화**\n",
    "\\\n",
    "\\\n",
    "sample에서 수학 점수를 3개의 구간으로 나누고 싶다 << 여기서 사용하는 메소드가 **cut**\n",
    "\\\n",
    "\\\n",
    "특정 컬럼의 데이터를 특정 구간으로 나누고자 할 때 cut() 사용\n",
    "\\\n",
    "동일한(유사한) 길이(값의 범위)로 나눕니다.\n",
    "\\\n",
    "`pd.cut(df[\"math\"], 3)`\n",
    "\\\n",
    "\\\n",
    "값의 범위에 대한 labeling을 해주면 데이터를 더 쉽게 분석 가능하다.\n",
    "\\\n",
    "\\\n",
    "`pd.cut(df[\"math\"], 3, labels = False)`\n",
    "\\\n",
    "인덱스 번호처럼 0부터 시작하는 번호가 부여된다.\n",
    "\\\n",
    "\\\n",
    "나눈 구간별로 그룹화를 진행한다\n",
    "\\\n",
    "`df2 = df[\"math\"].groupby(df1)`\n",
    "\\\n",
    "\\\n",
    "**그룹화한 데이터 기초통계(count, mean, std, min, max)**\n",
    "\\\n",
    "agg() 함수 사용\n",
    "\\\n",
    "`df2.agg([\"count\",\"mean\",\"std\",\"min\",\"max\"])`\n",
    "\\\n",
    "\\\n",
    "유사한 값들(동일한 범위가 아닌 유사한 값들)끼리 구간 나누기\n",
    "\\\n",
    "구간이 많아지면, 해당 구간에 없는 값이 생길수 도 있음\n",
    "\\\n",
    "해당 구간에 존재하는 값이 없을 경우에는 조회 안됨\n",
    "\\\n",
    "\\\n",
    "(범위는 만들어져 있는데 해당 구간에 속하는 값이 없을 수도 있다는 뜻)\n",
    "\\\n",
    "\\\n",
    "`pd.qcut(df[\"math\"],5,labels=False)`\n",
    "\\\n",
    "\\\n",
    "**구간 값을 지정하고 싶을 때.. 보통 1부터 ~시작...**\n",
    "\\\n",
    "(0구간이라고 하기 좀 그러니까)\n",
    "\\\n",
    "`import numpy as np`\n",
    "\\\n",
    "`pd.qcut(df[\"math\"],5,labels=np.arange(1, 6, 1))`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O8m76iGrZbjs"
   },
   "source": [
    "**원-핫 인코딩**\n",
    "\\\n",
    "\\\n",
    "범주를 컬럼으로 데이터화 하고자 할때 사용\n",
    "\\\n",
    "\\\n",
    "0과 1의 값을 사용\n",
    "\\\n",
    "`df_onehot = pd.get_dummies(df)`\n",
    "\\\n",
    "범주로 구분될 수 있는 모든 데이터들(category)에 대해 컬럼으로 올려버린다!\n",
    "\\\n",
    "\\\n",
    "컬럼으로 올려놓으면 x좌표, y좌표 등으로 찍을 수 있게 되기 때문에 시각화할때 아주 수월해진다.\n",
    "\\\n",
    "\\\n",
    "특정 컬럼에 대한 원-핫 인코딩하기\n",
    "\\\n",
    "`df_onehot2 = pd.get_dummies(df[\"sex\"])`\n",
    "\\\n",
    "\\\n",
    "\\\n",
    " 성별로 원핫인코딩한 변수를 이용해서 \n",
    "\\\n",
    " 성별로 몇 명씩 있는지 확인해 주세요...\n",
    "\\\n",
    "`df_onehot2.sum()`\n",
    "\\\n",
    "이거 한 줄이면 끝! for문 필요없다..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QGKmWNqphILI"
   },
   "source": [
    "**데이터 전치**\n",
    "\\\n",
    "\\\n",
    "전치 : 행과 열의 위치를 바꿀 때 사용\n",
    "\\\n",
    "컬럼은 행 인덱스로 사용\n",
    "\\\n",
    "행은 컬럼으로 사용\n",
    "\\\n",
    "\\\n",
    "`df.T`\n",
    "\\\n",
    "\\\n",
    "컬럼명으로 써야할 데이터가 행으로 나올 때 사용하면 된다!\n",
    "\\\n",
    "\\\n",
    "<문제>\n",
    "\\\n",
    "데이터에서 반별 성별 과학점수의 평균을 조회해 주세요\n",
    "\\\n",
    "반은 행, 성별은 컬럼으로 표시\n",
    "\\\n",
    "반은 A~C, 성별은 m,w\n",
    "\\\n",
    "`df_pivot = df.pivot_table(index = \"class\",\n",
    "                         columns=\"sex\",\n",
    "                         values=\"science\",\n",
    "                         aggfunc=\"mean\")`\n",
    "\\\n",
    "\\\n",
    "groupby로도 해보고, pivot_table로도 해보며 데이터를 재구조화 하기!\n",
    "\\\n",
    "\\\n",
    "반별 성별로 그룹화하여 과학점수의 평균을 구하고, \n",
    "데이터프레임 형태로 조회해 주세요..\n",
    "\\\n",
    "행은 행인덱스 번호, 컬럼에는 반, 성별, 과학점수 평균\n",
    "\\\n",
    "`df_temp = df.groupby([\"class\",\"sex\"])[\"science\"].mean().reset_index()`\n",
    "\\\n",
    "\\\n",
    "이렇게 하면 pivot_table 형태를 데이터 프레임 형태로 바꿀 수 있다! 여기서 Drop=True로 해버리면 인덱스 값 활용을 못하기 때문에 살려두자!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NY4RFRdf3RpM"
   },
   "source": [
    "#2023년 1월 11일"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RkLYfwkl3WZc"
   },
   "source": [
    "8day 폴더를 생성!\n",
    "\\\n",
    "\\\n",
    "교통데이터에서 시간대별, 체류시간 등을 계산할 때 숫자로 계산하는 것과 날짜로 계산하는 것은 다르다.\n",
    "\\\n",
    "날짜 타입으로 바꿔서 조작이 가능\n",
    "\\\n",
    "\\\n",
    "일반적으로 '-'가 들어있으면 문자열, 정수값만 들어있으면 int 타입으로 인지.\n",
    "\\\n",
    "\\\n",
    "시간 단위 분석을 ***'시계열 분석'*** 이라고 함\n",
    "\\\n",
    "\\\n",
    "유형 : 0000-00-00, 0000/00/00, 0000.00.00, 00000000 \n",
    "\\\n",
    "위 4가지가 날짜 타입으로 바꿀 수 있는 일반적인 유형이다.\n",
    "\\\n",
    "\\\n",
    "해당 유형들을 자동으로 인지해서 연/월/일로 변환 가능한 함수가 있다.\n",
    "\\\n",
    "\\\n",
    "`dates = [\"2020-01-01\", \"2020-03-01\", \"2020-09-01\"]`\n",
    "\\\n",
    "`ts_dates = pd.to_datetime(dates)`\n",
    "\\\n",
    "\\\n",
    "**pd.to_datetime()** 함수로 변환 후 00시, 00분, 00초가 자동으로 붙는다.\n",
    "\\\n",
    "\\\n",
    "freq는 유형을 의미. 어떤 값을 뽑아낼 것인지\n",
    "\\\n",
    "\\\n",
    "날짜 타입에서 특정 기간(년, 년-월, 년-월-일)형태로 추출하기\n",
    "\\\n",
    "날짜 타입을 기간형태로 추출하기 위해서는 to_period() 함수로 변환해야함\n",
    "\\\n",
    "기간형태 지정은 freq을 이용\n",
    "\\\n",
    " freq = \"D\" : yyyy-mm-dd 형태의 일자까지 조회\n",
    "\\\n",
    "`pr_day = ts_dates.to_period(freq = \"D\")`\n",
    "\\\n",
    "위와 같이 입력시 연-월-일 까지 출력, D대신 M을 넣으면 연-월까지, Y를 넣으면 연도만 출력\n",
    "\\\n",
    "\\\n",
    "timeseries.csv파일을 읽어들여서 실습시작\n",
    "\\\n",
    "\\\n",
    "**행 단위 조회시 사용하는 것들(복습)**\n",
    "\\\n",
    "`df[\"new_Date\"][0]`\n",
    "\\\n",
    "`df[\"new_Date\"].iloc[0]`\n",
    "\\\n",
    "`df[\"new_Date\"].loc[0]`\n",
    "\\\n",
    "\\\n",
    "특정값 타입확인은 type()에 넣어서 확인!\n",
    "\\\n",
    "\\\n",
    "컬럼 자체를 삭제할 땐 dataframe.Drop([\"컬럼이름\"], axis=1)로 삭제하면 된다!\n",
    "\\\n",
    "axis=1이 컬럼단위, axis=0은 행단위\n",
    "\\\n",
    "\\\n",
    "inplace 속성은 현재 실행단계에서 수정된 부분을 메모리에 반영시킨다! inplace=True로 설정하면 됨\n",
    "\\\n",
    "\\\n",
    "**시계열 데이터 형태로 변환하기**\n",
    "\\\n",
    "\\\n",
    "인덱스 값이 날짜 타입 데이터면 시계열 데이터 형태라고 볼 수 있다!\n",
    "\\\n",
    "\\\n",
    "**인덱스값 변경하기 : `set_index()`함수 사용**\n",
    "\\\n",
    "\\\n",
    "날짜타입으로 변환된 인덱스면 info()로 조회했을 때 rangeindex가 아니라 Datetimeindex로 표시됨!\n",
    "\\\n",
    "\\\n",
    "**기간 설정하기**\n",
    "\\\n",
    "\\\n",
    "`timestamp_df = pd.date_range(start = \"2020-01-01\",\n",
    "                            end = None,\n",
    "                            periods = 6,\n",
    "                            freq = \"Y\",\n",
    "                            tz = \"Asia/Seoul\")`\n",
    "\\\n",
    "\\\n",
    "start : 기간의 시작값\n",
    "\\\n",
    "end : 기간의 끝값\n",
    "\\\n",
    "periods : 생성할 기간의 갯수\n",
    "\\\n",
    "freq : 시간 간격 설정(Y = 년단위, M = 월단위, D = 일단위), 여기서는 연도단위로 증가시키면서 기간을 만들겠다는 의미\n",
    "\\\n",
    "tz : 시간대 지정(국가)\n",
    "\\\n",
    "\\\n",
    "period_range() 사용\n",
    "\\\n",
    "`pr_y = pd.period_range(start = \"2020-01-01\",\n",
    "                      end = None,\n",
    "                      periods = 3,\n",
    "                      freq = \"Y\")`\n",
    "\\\n",
    "\\\n",
    "period_range는 date_range와 달리 freq에 지정한 값만 나온다.\n",
    "\\\n",
    "\\\n",
    "Y대신 2Y를 집어넣으면 연도가 2씩 증가하는 것을 확인할 수 있다!\n",
    "\\\n",
    "\\\n",
    "M을 집어넣으면 연-월까지 표현가능\n",
    "\\\n",
    "\\\n",
    "Y:연도, M:월, D:일, H:시, min:분, s:초\n",
    "\\\n",
    "까지 표현이 가능하다!\n",
    "\\\n",
    "\\\n",
    "2020년 1월 1일부터 시작해서 3개의 기간을 생성\n",
    "\\\n",
    " 2일, 2시간, 2분, 2초씩 증가되도록 3개 구간을 만들어주세요\n",
    "\\\n",
    "`pr_dhmins = pd.period_range(start = \"2020-01-01\",\n",
    "                      end = None,\n",
    "                      periods = 3,\n",
    "                      freq = \"2D 2H 2MIN 2S\")`\n",
    "\\\n",
    "\\\n",
    "위와 같이 여러 값들을 순차적으로 바꿀 수도 있다!\n",
    "\\\n",
    "(시분초가 들어가면 연/월을 바꾸는게 쉽지않다!, 위에서 day까지만 같이 바꿀 수 있고 m, y까지 같이 넣으면 오류발생)\n",
    "\\\n",
    "\\\n",
    "**Date컬럼에서 연/월/일 추출하기!**\n",
    "\\\n",
    "\\\n",
    "날짜 타입 컬럼에서 년도 추출하기\n",
    "\\\n",
    "`df[\"new_Date\"].dt.year`\n",
    "\\\n",
    "\\\n",
    "df[\"new_Date\"]의 시리즈를 dt로 DatetimeProperties로 바꾸고, year로 속성을 결정해주면 연도만 뽑아낼 수 있다!\n",
    "\\\n",
    "\\\n",
    "`df[\"Date_ymd\"] = df[\"new_Date\"].dt.to_period(freq=\"D\")`\n",
    "\\\n",
    "를 사용하면 연-월-일을 다 같이 뽑아낼 수 있다.\n",
    "\\\n",
    "\\\n",
    "**인덱스 값**을 이용해서 조회하려면 `.loc[[]]`를 이용하자!\n",
    "\\\n",
    "\\\n",
    "2015-07-02 ~ 2018-06-28 까지의 행을 조회해 주세요... 인덱스 값 이용\n",
    "\\\n",
    "`df.loc[\"2015-07-02\":\"2018-06-28\"]`\n",
    "\\\n",
    "위 방식으로 날짜의 범위를 지정해서 조회가 가능!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7HnzA64Mmewv"
   },
   "source": [
    "**시계열 데이터로 시각화하기**\n",
    "\\\n",
    "\\\n",
    " x축 : 인덱스값\n",
    "\\\n",
    " y축 : 컬럼들 전체 데이터 중에 최소~최대 범위값(숫자데이터)\n",
    "\\\n",
    " 선  : 모든 컬럼들(숫자데이터)\n",
    "\\\n",
    "`df.plot()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HiijdqNsnQv-"
   },
   "source": [
    "**데이터 시각화의 종류**\n",
    "\\\n",
    "\\\n",
    "앤스컴 데이터는 수치 데이터와 시각화된 데이터의 차이점을 알 수 있게 해주는 연습용 데이터이다. (전세계적으로 가장 많이 쓰는 예제)\n",
    "\\\n",
    "\\\n",
    "앤스컴 데이터를 읽어들인 후, dataset을 기준으로 그룹화하였다.\n",
    "\\\n",
    "\\\n",
    "ans 에서 dataset 값이 I인 것만 추출\n",
    "\\\n",
    "\\\n",
    "`data1 = ans[(ans[\"dataset\"] == \"I\") == True]`\n",
    "\\\n",
    "\\\n",
    "**data1~data4까지 그래프를 4개의 공간에 동시에 그리기**\n",
    "\\\n",
    "\\\n",
    "그래프를 그리기 위한 객체 받아 오기\n",
    "\\\n",
    "`fig = plt.figure()`\n",
    "\\\n",
    "\\\n",
    "4개 각각의 그래프를 그리기 위한 공간 만들기\n",
    "\\\n",
    "subplot 함수 사용\n",
    "\\\n",
    "`ax1 = fig.add_subplot(2, 2, 1)`\n",
    "\\\n",
    "`ax2 = fig.add_subplot(2, 2, 2)`\n",
    "\\\n",
    "`ax3 = fig.add_subplot(2, 2, 3)`\n",
    "\\\n",
    "`ax4 = fig.add_subplot(2, 2, 4)`\n",
    "\\\n",
    "\\\n",
    " 첫번째 값 : 행을 의미함\n",
    "\\\n",
    " 두번째 값 : 열을 의미함\n",
    "\\\n",
    " 세번째 값 : 행렬 중 어느 위치에 들어갈지 순서 지정\n",
    "2행 2열의 공간을 생성\n",
    "\\\n",
    "\\\n",
    "subplot에 제목 넣기 : set_title() 함수 사용\n",
    "\\\n",
    "`ax1.set_title(\"data1\")`\n",
    "\\\n",
    "\\\n",
    "그래프의 위/아래 사이에 겹쳐서 나오는 부분을 해소하기 위해 간격 조정을 합니다. **tight_layout()** 함수 사용\n",
    "`fig.tight_layout()`\n",
    "\\\n",
    "\\\n",
    "모든 그래프는 위에서 바라보는 형태로 층층이 겹치면서 그려내는 형태. 가장 맨 밑엔 subplot, 그 다음 층엔 subplot의 title, 그리고 등등\n",
    "\\\n",
    "\\\n",
    "데이터를 넣어서 그림 그리기 : 점으로 표시\n",
    "\\\n",
    "`ax1.plot(data1[\"x\"],data1[\"y\"],'x')`\n",
    "\\\n",
    "`ax2.plot(data2[\"x\"],data2[\"y\"],'x')`\n",
    "\\\n",
    "`ax3.plot(data3[\"x\"],data3[\"y\"],'x')`\n",
    "\\\n",
    "`ax4.plot(data4[\"x\"],data4[\"y\"],'x', c=\"orange\")`\n",
    "\\\n",
    "\\\n",
    "또, 속성 c값을 활용해서 점의 색상도 정할 수 있다. 오렌지 색은 orange, 빨간색은 red 혹은 r\n",
    "\\\n",
    "\\\n",
    "fig.suptitle(\"제목\")으로 대제목을 정할 수 있고 suptitle이 subtitle과 같은 위치에 있으므로 fig.tight_layout()을 한번 더 거치면 자연스러워 진다!\n",
    "\\\n",
    "\\\n",
    "data1은 우상향 데이터\n",
    "\\\n",
    "\\\n",
    "**그래프 종류 알아보기**\n",
    "\\\n",
    "그래프의 종류를 나열. 나중에 시각화할 때 대입하기만 하면 된다.\n",
    "\\\n",
    "\\\n",
    "`list1 = [1,2,3]`\n",
    "\\\n",
    "`list2 = [1,2,3]`\n",
    "\\\n",
    "`plt.title(\"Line\")`\n",
    "\\\n",
    "`plt.plot(list1, list2, marker = \"o\")`\n",
    "\\\n",
    "\\\n",
    "로 좀 더 확실한 구간 관찰 가능!\n",
    "\\\n",
    "\\\n",
    "**범례 추가하기**\n",
    "\\\n",
    "\\\n",
    "범례 추가하기, (legend 뜻은 전설말고도 범례라는 뜻이 있다!)\n",
    "\\\n",
    "plt.title(\"Legend\")\n",
    "\\\n",
    "그래프 2개 그리기\n",
    "\\\n",
    "`plt.plot([1, 2, 3, 4], label = \"asc\")` #증가\n",
    "\\\n",
    "`plt.plot([4, 3, 2, 1], label = \"desc\")` #감소\n",
    "\\\n",
    "label에 대한 범례 추가\n",
    "\\\n",
    "`plt.legend()` <<범례 추가함수\n",
    "\\\n",
    "`plt.show()`\n",
    "\\\n",
    "\\\n",
    "`plt.xlabel(\"\")`과 `plt.ylabel(\"\")`을 이용하여 x축, y축의 이름을 정할 수 있다.\n",
    "\\\n",
    "\\\n",
    "선 모양 변경하기\n",
    "\\\n",
    "`plt.plot([1, 2, 3, 4], label=\"line\", linestyle = \"-\")`\n",
    "\\\n",
    "`plt.plot([4, 3, 2, 1], label=\"dashed\", linestyle = \"--\")`\n",
    "\\\n",
    "`plt.plot([2, 1, 1, 2], label=\"dotted\", linestyle = \":\")`\n",
    "\\\n",
    "\\\n",
    "\\ \n",
    "c : 색상\n",
    "\\ \n",
    "lw : 선의 굵기\n",
    "\\ \n",
    "ls : 선의 스타일\n",
    "\\\n",
    " marker : 값의 위치에 표시할 마커 형태(기본 : o, s, x)\n",
    "\\\n",
    "ms : 마커의 전체 사이즈(크기)\n",
    "\\ \n",
    "mec : 마커의 테둘 색상\n",
    "\\ \n",
    "mew : 마커 테두리 사이즈(크기)\n",
    "\\ \n",
    "mfc : 마커 내부의 채우기 색상\n",
    "\\\n",
    "`plt.plot([10, 20, 30, 40],[1, 4, 9, 16],\n",
    "        c = \"lightgreen\", lw=5, ls=\"--\", marker = \"o\", ms=15, mec=\"g\", mew=5, mfc=\"r\")`\n",
    "x축 값의 범위 지정\n",
    "`plt.xlim(0,50)`\n",
    "\n",
    "`plt.ylim(-10,30)`\n",
    "\n",
    "`plt.show()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xLCdR0XBTofK"
   },
   "source": [
    "seaborn 내장 데이터셋 활용해서 시각화 하기\n",
    "\\\n",
    "\\\n",
    "seaborn을 이용해서 시각화하면 파스텔톤으로 좀 더 이쁘다고 한다.\n",
    "\\\n",
    "\\\n",
    "데이터프레임에서 제공해 주는 기본 [선그래프]\n",
    "\\\n",
    "선 그래프는 kind 생략가능(default로 설정)\n",
    "\\\n",
    "`tips.plot(kind = \"line\")`\n",
    "\\\n",
    "\\\n",
    "`tips.plot(kind = \"hist\")`\n",
    "\\\n",
    "\\\n",
    "`tips.plot(kind = \"box\")`\n",
    "\\\n",
    "\\\n",
    "선그래프는 여러개 컬럼의 데이터들의 탐색적 데이터 분석을 할 때 사용\n",
    "\\\n",
    "\\\n",
    "탐색적 데이터 분석 : 방법론\n",
    "\\\n",
    "*EDA라고 보통 부릅니다. (분석 방법론 이름으로 주로 사용)*\n",
    "\\\n",
    "\\\n",
    "막대 그래프는 보통 현황분석(빈도 분석) 시에 사용,(누가 크고 누가 작은지)\n",
    "\\\n",
    "\\\n",
    "박스 플롯은 전처리 시에 ex)이상치 처리에 사용한다!\n",
    "\\\n",
    "\\\n",
    "matplotlib의 plot()활용해서 그려보기\n",
    "\\\n",
    "`plt.plot(tips.total_bill)`\n",
    "\\\n",
    "\\\n",
    "산점도 그래프\n",
    "\\\n",
    "두 데이터 간의 관계를 확인할 때 주로 사용됨\n",
    "\\\n",
    "데이터의 분포 확인 가능, 이상치 데이터를 대략 확인 가능\n",
    "\\\n",
    "`plt.scatter(tips.total_bill, tips.tip)`\n",
    "\\\n",
    "\\\n",
    "`plt.hist(tips.day)`로 히스토그램을 사용\n",
    "\\\n",
    "\\\n",
    "**seaborn으로 시각화하기**\n",
    "\\\n",
    "\\\n",
    " seaborn에서 제공해주는 데이터셋 중 주로 사용하는 데이터들\n",
    "\\\n",
    "\\\n",
    "붓꽃 데이터셋\n",
    "\\\n",
    "`iris = sns.load_dataset(\"iris\")`\n",
    "\\\n",
    "\\\n",
    "보통 꽃잎의 사이즈로 분류할 때 많이 사용\n",
    "\\\n",
    "\\\n",
    "타이타닉호 데이터셋\n",
    "\\\n",
    "`titanic = sns.load_dataset(\"titanic\")`\n",
    "\\\n",
    "\\\n",
    "생존자 분류, 어떤 컬럼끼리 조합했을 때 생존확률이 높을지 등등\n",
    "\\\n",
    "\\\n",
    "팁 데이터셋\n",
    "\\\n",
    "`tips = sns.load_dataset(\"tips\")`\n",
    "\\\n",
    "\\\n",
    "여객운송 데이터셋\n",
    "\\\n",
    "`flights = sns.load_dataset(\"flights\")`\n",
    "\\\n",
    "\\\n",
    "stripplot 시각화\n",
    "\\\n",
    "\\\n",
    "기본 팔레트 배경 설정\n",
    "`sns.set_palette(\"pastel\")`\n",
    "\\\n",
    "\\\n",
    "stripplot 모양 지정\n",
    "\\\n",
    "`sns.stripplot(x = \"day\", y = \"total_bill\", data=tips)`\n",
    "\\\n",
    "\\\n",
    "논문 작성시 제목이나 표에 들어가는 모든 텍스트는 영문으로 작성해야함! (데이터는 상관x)\n",
    "\\\n",
    "\\\n",
    "막대그래프\n",
    "\\\n",
    "\\\n",
    "평균치를 빠르게 집계해서 시각화 가능\n",
    "\\\n",
    " 막대그래프 위의 선 : 오차 막대(error bar)라고 칭함\n",
    "\\\n",
    "오차막대는 막대 그래프 위에서 끝 막대를 기준으로 반반씩\n",
    "\\\n",
    " 오차막대의 길이가 작을수록 좋음(편차가 클수록 막대의 길이가 길어지고 작을수록 길이가 짧아진다.)\n",
    "\\\n",
    "\\\n",
    "`sns.barplot(x=\"sex\", y=\"tip\", data=tips)`\n",
    "\\\n",
    "\\\n",
    "오차막대 숨기기:\n",
    "\\\n",
    "`sns.barplot(x=\"sex\", y=\"tip\", estimator = len, data=tips)`\n",
    "\\\n",
    "\\\n",
    "그래프는 표현하고 싶은 데이터의 개수를 모두 표현할 수 없다! -- 최대 3개까지는 가능!\n",
    "\\\n",
    "\\\n",
    "성별/요일별 tip 데이터 시각화\n",
    "\\\n",
    "`sns.barplot(x=\"sex\", y=\"tip\", hue=\"day\", data=tips)`\n",
    "\\\n",
    "\\\n",
    " 박스 플롯 시각화\n",
    "\\\n",
    "`sns.boxplot(x=\"sex\", y=\"tip\", data=tips)`\n",
    "\\\n",
    "\\\n",
    "박스플롯 가로/세로 지정: orient\n",
    "\\\n",
    " orient = v : 수직으로 표현(디폴트)\n",
    "\\\n",
    " orient = h : 수평으로 표현\n",
    "`sns.boxplot(data=tips, orient=\"h\")`\n",
    "\\\n",
    "\\\n",
    "**커널밀도그래프**\n",
    "\\\n",
    " 히스토그램보다 부드러운 형태의 분포 곡선으로 시각화\n",
    "\\\n",
    "`sns.kdeplot(tips.tip)`\n",
    "\\\n",
    "\\\n",
    "**커널 밀도 그래프와 히스토 그램을 하나의 그래프로 표현하는 함수**\n",
    "\\\n",
    "<<매우 유용하나 seaborn v0.14.0 업데이트때 없어진다고 함..\n",
    "\\\n",
    "`sns.distplot(tips.tip)`\n",
    "\\\n",
    "이 그래프에서 선그래프를 넘어나는 막대그래프들은 이상치라고도 볼 수 있음\n",
    "\\\n",
    "\\\n",
    "시각화할 땐 **이쁜게** 중요!\n",
    "\\\n",
    "프로젝트 평가에서 ppt의 화려함이 50%!\n",
    "\\\n",
    "공모전에서도 ppt의 화려함과 발표자의 말빨이 입상을 좌우\n",
    "\\\n",
    "\\\n",
    "히스토그램은 막대그래프가 모두 붙어있는것!\n",
    "\\\n",
    "\\\n",
    "여러 그래프를 하나로 그리기\n",
    "\\\n",
    " kind : 그래프 종류 지정\n",
    "\\\n",
    " scaatter : 산점도와 막대 그래프를 동시에 시각화함\n",
    "\\\n",
    "`sns.jointplot(x=\"total_bill\", y=\"tip\",data=tips, kind=\"scatter\")`\n",
    "\\\n",
    "<<설명력이 좋다고 할 수 있는 그래프중 하나\n",
    "\\\n",
    "\\\n",
    "kde : 커널밀도와 선그래프를 동시에 시각화함\n",
    "\\\n",
    "`sns.jointplot(x=\"total_bill\", y=\"tip\",data=tips, kind=\"kde\")`\n",
    "\\\n",
    "\\\n",
    "등고선의 간격이 좁을 수록 밀집도가 높다.(중앙 원 기준) 간격이 넓어질 수록 밀집도가 낮은 것.\n",
    "\\\n",
    "\\\n",
    "**다차원 복합 데이터 시각화**\n",
    "\\\n",
    "swarm : 데이터를 나타내는 점이 겹치지 않도록 표현(일반적으로 많이 사용)\n",
    "\\\n",
    "violin : swarm의 점의 전체 모양을 바이올린 모양으로 표현\n",
    "\\\n",
    "catplot : 색상과 행 등을 동시에 사용하여 3개 이상의 범주값의 분포 변화를 시각화\n",
    "\\\n",
    "`sns.catplot(x=\"day\", y=\"total_bill\", hue=\"sex\",kind=\"swarm\",data=tips)`\n",
    "\\\n",
    "\\\n",
    "(x,y말고 또 들어가는 값이 있다면 항상 'hue'!)\n",
    "\\\n",
    "\\\n",
    "catplot의 violin과 동일함\n",
    "\\\n",
    "`sns.violinplot(x=\"day\",y=\"total_bill\",data=tips)`\n",
    "\\\n",
    "\\\n",
    "다차원 시각화 : 여러 컬럼의 데이터 시각화\n",
    "\\\n",
    "크로스 체크 가능\n",
    "\\\n",
    "`sns.pairplot(tips)`\n",
    "\\\n",
    "막대그래프가 나온건 자기 자신!\n",
    "\\\n",
    "pairplot으로 상관관계를 체크 가능, 해당 예시에서는 total_bill과 tip의 관계성이 있는 분포를 가지고 있다는 것을 확인할 수 있다.\n",
    "\\\n",
    "\\\n",
    "다차원 상관도\n",
    "\\\n",
    "`sns.pairplot(tips,hue=\"sex\")`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tc_j_JZquIjJ"
   },
   "source": [
    "**지도 시각화**\n",
    "\\\n",
    "\\\n",
    "스타벅스 위도 경도 수치를 이용!, 위도,경도가 없다면 주소를 가지고 위-경도를 뽑아내야한다.\n",
    "\\\n",
    "\\\n",
    "지도 시각화를 할 때 folium이라는 라이브러리를 사용\n",
    "\\\n",
    "\\\n",
    "주피터에서도 라이브러리를 설치할 수 있지만 웬만하면 아나콘다 파워쉘 프롬프트에서 설치하는 걸 추천! 가끔씩 깨질 수도 있음\n",
    "\\\n",
    "\\\n",
    "설치하려는 가상공간을 activate한 후, conda install -c conda-forge folium입력. -c는 conda의 채널을 선택\n",
    "\\\n",
    "\\\n",
    "지도시각화 라이브러리 불러들이기\n",
    "\\\n",
    "\\\n",
    " 라이브러리 설치방법 3가지\n",
    "\\\n",
    "conda install -c conda-forge folium\n",
    "\\\n",
    " <<가장 세심하게 설치\n",
    "\\\n",
    "\\\n",
    " conda install folium\n",
    "\\\n",
    "<<위 방법이 안될때\n",
    "\\\n",
    "\\\n",
    " pip install folium\n",
    "\\\n",
    "<<그래도 안될때, 웬만해선 다 설치를 하나, 버전 체크를 잘 안해준다..\n",
    "\\\n",
    "\\\n",
    "주피터에서 설치시 : 맨 앞에 느낌표(!)만 붙이면 됨..\n",
    "\\\n",
    "!conda install -c ....."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IQr4U7tQw7zT"
   },
   "source": [
    "json파일은 대부분 딕셔너리 형태!\n",
    "\\\n",
    "\\\n",
    "key가 있고 value, 그안에 딕셔너리, 리스트 속 리스트, 리스트 속 딕셔너리 등등의 구조로 되어있다!<<얘를 풀어헤칠 때 사용하는 라이브러리가 json\n",
    "\\\n",
    "\\\n",
    "지도 그리기\n",
    "```\n",
    "starbucks_map = folium.Map(\n",
    "     \n",
    "     최초에 보여줄 지도 위치 지정하기 (지도 중심점 좌표)\n",
    "     [위도, 경도] 지정\n",
    "    \n",
    "    location = [37.573050, 126.979189],\n",
    "    \n",
    "     지도 스타일 지정하기 : tiles\n",
    "     openstreetmap : 도시형 건물 등 일반적으로 사용되는 스타일\n",
    "     Stamen Terrain : 산림 위주로 보여주는 스타일\n",
    "     cartodbpositron : 하천이나 도로(길) 위주로 보여주는 스타일\n",
    "    tiles = \"openstreetmap\",\n",
    "    \n",
    "     최초에 보여질 지도 zoom 사이즈 지정\n",
    "    zoom_start = 50\n",
    ")\n",
    "starbucks_map\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "### 스타벅스 매장 위치를 표시하기\n",
    "# - 지도 시각화 시 여러 좌표의 위치를 표시할 때는 반복문 사용\n",
    "for idx in seoul_starbucks.index : \n",
    "    # 위/경도 데이터 변수처리\n",
    "    lat = seoul_starbucks.loc[idx, \"위도\"]\n",
    "    lng = seoul_starbucks.loc[idx, \"경도\"]\n",
    "    \n",
    "    # 지도에 표시할 마킹 모양 등 스타일 지정\n",
    "    folium.CircleMarker(\n",
    "        # 마킹 위치 지정\n",
    "        location = [lat, lng],\n",
    "        fill_color = \"green\",\n",
    "        fill_opacity = 1,\n",
    "        color = \"yellow\",\n",
    "        weight = 1,\n",
    "        radius = 3\n",
    "        \n",
    "        # 사용할 지도형태 지정하기 : 위에서 정의하였음(seoul_starbucks)\n",
    "    ).add_to(starbucks_map)\n",
    "```\n",
    "\\\n",
    "fill_opacity는 불투명도를 결정\n",
    "\\\n",
    "\\\n",
    "(스타벅스 리저브 매장은 원두 직수입 매장)\n",
    "```\n",
    "### 매장 타입 별로 위치 표시하기\n",
    "\n",
    "### 지도 그리기\n",
    "starbucks_map2 = folium.Map(\n",
    "    location = [37.573050, 126.979189],\n",
    "    tiles = \"openstreetmap\",\n",
    "    zoom_start = 11\n",
    ")\n",
    "\n",
    "for idx in seoul_starbucks.index :\n",
    "    ### 데이터 추출하기\n",
    "    lat = seoul_starbucks.loc[idx, \"위도\"]\n",
    "    lng = seoul_starbucks.loc[idx, \"경도\"]\n",
    "    store_type = seoul_starbucks.loc[idx, \"매장타입\"]\n",
    "    \n",
    "    ### 매장 타입별 색상 지정하기\n",
    "    fillColor = \"\"\n",
    "    size = 1\n",
    "    if store_type == \"general\" :\n",
    "        fillColor= \"gray\"\n",
    "        size = 3\n",
    "    elif store_type == \"reserve\" :\n",
    "        fillColor= \"blue\"\n",
    "        size = 5\n",
    "    elif store_type == \"generalDT\" :\n",
    "        fillColor= \"red\"\n",
    "        size = 5\n",
    "        \n",
    "    ### 표시할 마커 스타일 지정하기\n",
    "    folium.CircleMarker(\n",
    "        # 마킹 위치 지정\n",
    "        location = [lat, lng],\n",
    "        fill_color = fillColor, # 위 조건문에 의해 색상이 결정\n",
    "        fill = True,\n",
    "        # fill_opacity : 불투명도...\n",
    "        fill_opacity = 1,\n",
    "        color = fillColor,\n",
    "        weight = 1,\n",
    "        radius = 3\n",
    "    ).add_to(starbucks_map2)\n",
    "starbucks_map2\n",
    "```\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I7TJzmZDkNIq"
   },
   "source": [
    "질문 : tips에서 막대그래프 그렸을 때 y축 값이 왜 0-3인지<<막대 없애는 기준이 count하면서 정확하게 세기 때문(estimator)\n",
    "\\\n",
    "시간대별 분석할 때 어떤 식으로 집계하는지. 이용시작 시각을 기준으로 하는지, 1시-3시1분 사용자의 예시 등등"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PzaKWameAcaw"
   },
   "source": [
    "## 스터디 공지\n",
    "\\\n",
    "\\\n",
    "일단 강사님께서 추천해주시는 교재 등으로 개인적으로 공부해와서 서로 가르치는 식의 방향 제시하심\n",
    "\\\n",
    "\\\n",
    "스터디 일정 짜기\n",
    "\\\n",
    "스터디 장소, 일정 (강사님께서 내용 추천해주심)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w8M2bSR59J8x"
   },
   "source": [
    "# 2023년 1월 12일"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uKtf-ERS9MfA"
   },
   "source": [
    "**머신러닝이란?**\n",
    "\\\n",
    "\\\n",
    "알고리즘 : 어떠한 문제를 해결하기 위한 일련의 절차나 방법\n",
    "\\\n",
    "\\\n",
    "머신러닝 : 기계가 패턴을 학습하여 자동화하는 알고리즘\n",
    "\\\n",
    "\\\n",
    "유튜브는 개인이 유튜브 영상을 보는 패턴에 대해 학습하는 프로그램(머신러닝)을 만든 다음 그 패턴(알고리즘)에 맞게 다음 영상을 계속 추천\n",
    "\\\n",
    "\\\n",
    "주변에 있는 환경 데이터를 가지고 패턴을 확인하고, 결과를 도출 -> 이 수학적인 과정을 모델로 미리 만들어 놓음. 이 안에 들어갈 수 있는 데이터를 만들어내야함.\n",
    "\\\n",
    "\\\n",
    "머신러닝부터는 거의 패턴이 정해져있음. 알고리즘이 바뀌더라도 들어가는 데이터는 거의 비슷. 결과물의 해석이 중요!\n",
    "\\\n",
    "\\\n",
    "**사용사례**\n",
    "\\\n",
    "\\\n",
    "구매추천\n",
    "\\\n",
    "\\\n",
    "번역\n",
    "\\\n",
    "\\\n",
    "자율주행\n",
    "\\\n",
    "\\\n",
    "챗봇\n",
    "\\\n",
    "\\\n",
    "\\\n",
    "인공지능>머신러닝>딥러닝\n",
    "\\\n",
    "\\\n",
    "머신러닝: 데이터를 컴퓨터에 학습시켜 그 패턴과 규칙을 컴퓨터가 스스로 학습하도록 만드는 기술\n",
    "\\\n",
    "\\\n",
    "이전에는 사람이 지식을 직접 데이터베이스화한 후 컴퓨터가 처리하도록 프로그램으로 만듦\n",
    "\\\n",
    "\\\n",
    "머신러닝은 데이터르르 분류하는 **수학적모델**을 프로그래밍하여 데이터만 입력하면 **이미 만들어진 수학 모델**이 규칙으로 적용되어 여러문제를 풀 수 있음\n",
    "\\\n",
    "\\\n",
    "딥러닝: 머신러닝 기법중 신경망을 기반으로 사물이나 데이터를 **군집화**하거나 **분류**하는데 사용하는 기술\n",
    "\\\n",
    "\\\n",
    "현재 우리나라에서 컴퓨터 비전, 영상 분석쪽에 많이 사용중이라고 하심!\n",
    "\\\n",
    "\\\n",
    "일반적으로 예측은 회귀모델, 분류는 분류모델, (+앙상블 모델)을 많이 쓴다.\n",
    "\\\n",
    "\\\n",
    "**빅데이터와 머신러닝**\n",
    "\\\n",
    "\\\n",
    "빅데이터 : 기존의 데이터베이스로는 수집 저장 분석을 수행하기 어려울 만큼 방대한 양의 데이터\n",
    "\\\n",
    "-데이터베이스에서 기원\n",
    "\\\n",
    "\\\n",
    "빅데이터 시스템: 빅데이터를 다루기 위한 시스템\n",
    "\\\n",
    "\\\n",
    "빅데이터 엔지니어링: 빅데이터를 다루는 방법\n",
    "\\\n",
    "\\\n",
    "머신러닝과 별개로 발전해왔으나 대용량 데이터가 학습성능에 크게 영향을 미치는 오늘 날 머신러닝 분야에서 의미있게 사용됨.\n",
    "\\\n",
    "\\\n",
    "분석, 기획, 엔지니어링, 프로그래밍 파트 등등이 있다.\n",
    "\\\n",
    "\\\n",
    "엔지니어링 파트는 시스템을 만드는 것. 프로그래밍 등등 기술적인 파트.\n",
    "\\\n",
    "\\\n",
    "우리는 분석파트를 배우고 있는 것\n",
    "\\\n",
    "\\\n",
    "기존 데이터를 가지고 전처리를 하고, 머신러닝 알고리즘에 넣어서 모델이 생성. 생성된 모델로 새로운 데이터를 넣어서 예측!(혹은 분류)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "ZoLq2m6FuZx9",
    "XcOGrRdw9sI-",
    "Pj8fiWiqEznO",
    "sR_wqrGE9hRk",
    "yAFUXNqSD0aU",
    "TBg0hwgl11Ib",
    "0jSnk9edk9e5",
    "NY4RFRdf3RpM"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
